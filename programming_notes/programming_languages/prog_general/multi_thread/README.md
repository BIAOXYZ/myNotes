
# books

【[:star:][`*`]】 第 10 章 并行编程基础 https://foxsen.github.io/archbase/%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80.html
- > **10.2.1 单任务数据并行模型**
  * > 数据并行（Data Parallel）模型是指对集合或者数组中的元素同时（即并行）执行相同操作。数据并行编程模型可以在`SIMD`计算机上实现，为单任务数据并行；也可以在`SPMD`计算机上实现，为多任务数据并行。SIMD着重开发指令级细粒度的并行性，SPMD着重开发子程序级中粒度的并行性。单任务数据并行编程模型具有以下特点：
- > **10.2.2 多任务共享存储编程模型**
  * > 在共享存储编程模型中，运行在各处理器上的进程（或者线程）可以通过读/写共享存储器中的共享变量来相互通信。它与单任务数据并行模型的相似之处在于有一个单一的全局名字空间。由于数据是在一个单一的共享地址空间中，因此不需要显式地分配数据，而工作负载则可以显式地分配也可以隐式地分配。通信通过共享的读/写变量隐式地完成，而同步必须显式地完成，以保持进程执行的正确顺序。共享存储编程模型如`Pthreads`和`OpenMP`等。
- > **10.2.3 多任务消息传递编程模型**
- > **10.2.4 共享存储与消息传递编程模型的编程复杂度**
  * > 采用共享存储与消息传递编程模型编写的并行程序是在多处理器并行处理系统上运行的。先了解一下多处理器的结构特点，可以更好地理解并行编程模型。从结构的角度看，多处理器系统可分为共享存储系统和消息传递系统两类。***在共享存储系统中，所有处理器共享主存储器，每个处理器都可以把信息存入主存储器，或从中取出信息，处理器之间的通信通过访问共享存储器来实现。而在消息传递系统中，每个处理器都有一个只有它自己才能访问的局部存储器，处理器之间的通信必须通过显式的消息传递来进行***。消息传递和共享存储系统的原理结构如`图10.1`所示。从图中可以看出，在消息传递系统中，每个处理器的存储器是单独编址的；而在共享存储系统中，所有存储器统一编址。***典型的<ins>共享存储多处理器结构</ins>包括`对称多处理器机（Symmetric Multi-Processor，简称SMP）结构`、`高速缓存一致非均匀存储器访问（Cache Coherent Non Uniform Memory Access，简称CC-NUMA）结构`***。
  * > ![](https://foxsen.github.io/archbase/images/chapter10/Shared_storage_and_message_passing_programming.png)
  * > 下面举两个共享存储和消息传递程序的例子。第一个例子是通过积分求圆周率。积分求圆周率的公式如下：
  * > 第二个例子是矩阵乘法。矩阵乘法的算法大家都很熟悉，这里就不介绍了。`图10.3`给出了共享存储和消息传递并行程序。同样，由jia_alloc()分配的变量所有进程共享一份，而由malloc()分配的变量每个进程单独一份，因此在这个程序中消息传递并行程序需要更多的内存。在共享存储并行程序中，先由0号进程对A、B、C三个矩阵进行初始化，而其他进程通过jia_barrier()语句等待。barrier是并行程序中常用的同步方式，它要求所有进程都等齐后再前进。然后每个进程分别完成部分运算，再通过jia_barrier()等齐后由0号进程统一打印结果。消息传递并行程序与共享存储并行程序的最大区别是需要通过显式的发送语句send和接收语句recv进行多个进程之间的通信。先由0号进程进行初始化后发送给其他进程，每个进程分别算完后再发送给0号进程进行打印。在消息传递并行程序中要详细列出每次发送的数据大小和起始地址等信息，0号进程接收的时候还要把从其他进程收到的数据拼接在一个矩阵中，比共享存储并行程序麻烦不少。
- > **10.3 典型并行编程环境**
  * > 本节主要介绍数据并行`SIMD`编程、***早期的共享存储编程标准`Pthreads`、目前主流的共享存储编程标准`OpenMP`和消息传递编程模型（`MPI`）等***。
- > **10.3.1 数据并行SIMD编程**
- > **10.3.2 POSIX编程标准**
  * > POSIX（Portable Operating System Interface）属于早期的共享存储编程模型。POSIXThreads（）即Pthreads）代表官方IEEE POSIX1003.1C_1995线程标准，是由IEEE标准委员会所建立的，主要包含线程管理、线程调度、同步等原语定义，体现为C语言的一套函数库。下面只简介其公共性质。
  * > 4.示例 以下程序示例用数值积分法求π的近似值。
- > **10.3.3 OpenMP标准**
- > **10.3.4 消息传递编程接口**
  * > `MPI（Message Passing Interface）`定义了一组消息传递函数库的编程接口标准。1994年发布了MPI第1版MPI-1,1997年发布了扩充版MPI-2，2012年发布了MPI-3标准。有多种支持MPI标准的函数库实现，开源实现有MPICH（由Argonne National Laboratory (ANL) 和Mississippi State University开发）、Open MPI 和LAM/MPI（由Ohio超算中心开发）等；商业实现来自于Intel、Microsoft、HP公司等。MPI编译器用于编译和链接MPI程序，支持C、C++、Fortran语言，如mpicc支持C语言、mpic++支持C++语言、mpif90支持Fortran90。MPI具有高可移植性和易用性，对运行的硬件要求简单，是目前国际上最流行的并行编程环境之一。
  * > 在`MPI`编程模型中，计算由一个或多个通过调用库函数进行消息收/发通信的进程所组成。在绝大部分MPI实现中，一组固定的进程在程序初始化时生成，在一个处理器核上通常只生成一个进程。这些进程可以执行相同或不同的程序（相应地称为单程序多数据（SPMD)或多程序多数据（MPMD)模式）。进程间的通信可以是点到点的或者集合（Collective）的。MPI只是为程序员提供了一个并行环境库，程序员用标准串行语言编写代码，并在其中调用MPI的库函数来实现消息通信，进行并行处理。

# tutorials

Visual C++ 中的并行编程 https://learn.microsoft.com/zh-cn/cpp/parallel/parallel-programming-in-visual-cpp
- Visual C++ 中的 OpenMP https://learn.microsoft.com/zh-cn/cpp/parallel/openmp/openmp-in-visual-cpp

# courses

Python 异步编程入门 https://www.lanqiao.cn/courses/1278 【`蓝桥云课`，即原`实验楼`】
