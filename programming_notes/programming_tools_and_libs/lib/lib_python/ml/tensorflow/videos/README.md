
TensorFlow 2.0 Tutorial For Beginners | TensorFlow Demo | Deep Learning & TensorFlow | Simplilearn https://www.youtube.com/watch?v=QPDsEtUK_D4

【北京大学】Tensorflow2.0 https://www.bilibili.com/video/BV1B7411L7Qt
- P1 0开篇语-全 https://www.bilibili.com/video/BV1B7411L7Qt?p=1
- 回复：
  * > 自己整理的学习笔记和收集的老师上课的ppt，已经上传到github上了 地址： https://github.com/dxc19951001/Study_TF2.0 欢迎大家clone与star

tensorflow2.0入门与实战 2019年最通俗易懂的课程 https://www.bilibili.com/video/BV1Zt411T7zE
- P2 2.1 最新 Tensorflow 2.3 CPU 版本极简安装 https://www.bilibili.com/video/BV1Zt411T7zE?p=2
- P7 6.多层感知器（神经网络）与激活函数 https://www.bilibili.com/video/BV1Zt411T7zE?p=7
  * > `1:50`: 单层神经元的缺陷：无法拟合“异或”运算。
  * > `2:15`: 神经元要求数据必须是线性可分的，“异或”问题无法找到一条直线分割两个类，这个问题使得神经网络的发展停滞了很多年。
  * > `4:45`: 多层感知器，在`输入层`和`输出层`之间有若干层的`隐藏层`。
- P9 8.逻辑回归与交叉熵 https://www.bilibili.com/video/BV1Zt411T7zE?p=9
  * > `3:00`: ***平方差所惩罚的是与损失为同一数量级的情形***。对于分类问题，我们最好使用`交叉熵损失函数`会更有效。交叉熵会输出一个更大的“损失”。
    >> //notes：个人觉得这个观点也算是有点道理吧。比如feature值都很大（房价），但是预测结果就是0和1（买或者不买），确实有量级的差距（但是这个时候一般不都是用feature value缩放嘛）。
