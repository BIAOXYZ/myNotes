
# 01

看看关系型数据库是怎么吊打Hadoop的 https://mp.weixin.qq.com/s/iNNPpT08fFGH4sZMPMBOOg
- > 这里仅仅以Oracle为例，下面这里有三个表，都是1亿数量级的规模。可以看到在这个量级下，Oracle的聚合分析，几乎都在100毫秒以下。硬件配置（操作系统层面识别到的）：22C  220G内存。使用了Oracle的In-Memory。
- > 不过毕竟有几个业务表上亿的数据的企业不多，而且也不会这样不带条件查询。如果带上条件那么1000万的2表关联结果是240毫秒。
- > 如果带上条件那么1000万的3表关联结果是390毫秒。
- > 以上一切的执行都是在OLTP数据库上直接执行的，只是因为用到了数据库自带的列式而已。
- > 这中间没有ETL，不需要CDC技术栈，不需要依赖时间戳。不需要数据加工，不需要数据清洗，也不需要制作成大宽表。以上这些不需要的总节约时间，单位都是以小时计的。更不用说这个SQL的执行时间，MapReduce的任务还没分解呢，我这里已经出结果了。
- > Hadoop在大家都是烂硬件的时代，依靠多机器全表IO打赢了单机器的全表IO（如果单机是用索引的话，那连20年前的单机也打不赢）。而对于现在HTAP或者说超融合的多模数据库来说，比如MySQL的HeatWave等列式存储的优势（这里包括MySQL Oracle PostgreSQL TiDB和OceanBase Polardb等等，不一一列举了），使得聚合运算场景上也是可以轻松分析。列数存储的分析对行式存储的分析优势明显，何况还少了巨大的中间环节的过程。有点降维打击的意思。
- > 之所以不少系统还是用OLTP+OLAP的原因，主要是在线的数据库本身不支持列式存储，所以必须要有CDC传输的过程。或者担心OLAP的场景乱用影响OLTP，那么就把数据复制一份，实时同步，单独运行OLAP。
