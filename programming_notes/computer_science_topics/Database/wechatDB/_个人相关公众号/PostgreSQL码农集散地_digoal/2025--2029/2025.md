
# 11

“强一致”和“最终一致”, 哪个才是未来方向 https://mp.weixin.qq.com/s/icxqyZX4OXPwYljiAacE9Q  【`11.29`】
- 回复：
  * > 本质上来说 业务重要 还是 技术重要。个人理解 业务更重要。最终都是以业务为导向的解决方案，这个不仅仅局限于互联网场景，金融行业如银联清算类 也是最终一致性。主要保障某个阶段是一致的 整个流程可追溯 大不了靠人来追平
  * > 所谓最终一致，也是在某个环节做了强一致了，否则单纯说最终一致就是没一致，没有可比性

DuckLake 更新, 支持Iceberg互换数据及Geometry类型等 https://mp.weixin.qq.com/s/cvfmRzZgkYQThj1vSUIHXw  【`11.28`】
- > DuckLake是DuckDB的一款扩展插件, 之前有过详细的架构介绍, 简单来说就是 `duckdb计算引擎 + 元数据管理 + 湖 + 表格存储格式` 的集合.
- > DuckLake 发布0.3, 带来诸多特性, 包括对DuckDB 1.4的特性引入、支持读写iceberg、支持geometry类型等.
- > 下面来看官方报道, 以下内容翻译自: https://duckdb.org/2025/09/17/ducklake-03.html

【[ :star: ][`*`]】 PostGIS 性能优化系列文章: bounding boxes https://mp.weixin.qq.com/s/ihbwfKbUBijm6m7F0IoTPg  【`11.26`】
- > PostGIS 性能优化系列文章: bounding boxes
  * > 在处理大规模地理空间数据时，您是否曾被一个核心痛点所困扰？您的数据库中存储着数以万计甚至百万计的 `Geometry data (几何数据)` ，但当您尝试执行一次简单的 `spatial join (空间连接)` 或查询时，系统却陷入了漫长的等待，仿佛被困在了大海捞针的窘境中？
  * > 尤其当您的 polygon (多边形) 形状复杂、横跨广阔区域（例如，跨洲的国家边界），PostGIS 赖以加速查询的 `spatial index (空间索引)` 效果就会大打折扣。这是因为那些巨大的、包裹着大量空白海洋区域的 `Bounding Boxes (边界框)` 正在悄悄地“毒害”您的 `R-tree indexes (R树索引)` ，让本该精确的查找变成了低效的大范围扫描。
  * > 好消息是： 您不必再忍受这种低效。
  * > 本文将揭示两种革命性的 PostGIS 函数 —— Decompose (分解) 和 Subdivide (细分) —— 如何彻底重塑您的几何图形，打造出更紧凑、更精准的 Bounding Boxes (边界框)，从而将原本耗时数秒的查询，提速至 4 倍以上！
  * > 如果您渴望让您的空间查询像闪电一样快，如果您想知道如何用少量的预处理成本换取巨大的长期性能收益，那么请务必继续阅读全文 。终极性能秘籍，即刻为您揭晓！
  * > 翻了一下历史文档, 发现2017年我写过两篇类似的文章, 参考如下：
    + > `《PostgreSQL 空间切割(st_split, ST_Subdivide)功能扩展 - 空间对象网格化 (多边形GiST优化)》`
    + > `《PostgreSQL 空间st_contains，st_within空间包含搜索优化 - 降IO和降CPU(bound box) (多边形GiST优化)》`
  * > 不过这篇又增加了Decompose( ST_Dump 可用于展开几何图形。它与 ST_Collect / GROUP BY 的操作相反，因为它会创建新行。例如，它可以用于将 MULTIPOLYGONS 展开为 POLYGONS ), 一起来学习一下吧, 以下内容来自:
  * > https://www.crunchydata.com/blog/postgis-performance-improve-bounding-boxes-with-decompose-and-subdivide

SQLite和PG的安全性居然不如DuckDB, 真的吗? https://mp.weixin.qq.com/s/eoSeBe1zXYWBlLMQp-kYwg  【`11.25`】
- > SQLite和PG的安全性居然不如DuckDB, 真的吗?
  * > 数据加密到底会给数据库的性能带来多大的影响?
  * > 如何配置既能保证健壮性, 又能保证性能?
  * > 除了数据文件加密, REDO日志要不要加密? 数据库审计日志要不要加密? 临时文件(例如外部排序用到的临时文件)要不要加密?
  * > 加密数据文件的密钥如何进行管理? 在内存中的加密密钥安全吗?
  * > 为什么SQLite3和PostgreSQL使用这么广泛的数据库, 居然没有提供内置的数据文件加密功能?
  * > 来看看DuckDB怎么做的? 《DuckDB 中的静态数据加密（Data-at-Rest Encryption）》 翻译自: https://duckdb.org/2025/11/19/encryption-in-duckdb

近日，DuckDB 悄悄发布1.4.2 LTS版，这个功能最亮眼 https://mp.weixin.qq.com/s/gFDml7prJ8orzVaynwcoWA  【`11.16`】
- > Vortex 存储的核心优势可归纳为“快、省、稳、易”四点：
  * > 1.极速读取
    + > 随机访问比 Parquet 快 100–200 倍，全表扫描快 2–10 倍，适合交互式分析与实时查询。
	* > 2.高压缩低占用
    + > 采用级联压缩 + 可插拔压缩策略，压缩比与 zstd-Parquet 相当，却显著减少存储空间。
	* > 3.零拷贝无缝对接
    + > 与 Apache Arrow 零拷贝互转，避免序列化开销；支持 GPU 原位解压，未来可直接在 GPU 显存里解压数据，减少 CPU-GPU 间数据搬运。
  * > 4.丰富编码与计算下推
    + > 内置 FastLanes、ALP、FSST 等先进编码，可按列灵活选择；支持过滤下推、延迟统计信息填充，进一步降低 I/O 与计算成本。
- 回复：
  * > 其实`vortex` 是palvo 搞出来的f3 格式的工程版 normal 场景下确实压缩效率高一点 但是速度和 parquet 差不多

OceanBase 源码学习: 2.5 PL/SQL 支持系统 https://mp.weixin.qq.com/s/95VArSTfFzg46wqLkzZ_mA  【`11.10`】
- > PL/SQL 支持系统由多个相互关联的组件组成，这些组件处理从 PL/SQL 源代码解析到运行时(runtime)执行的完整生命周期。该系统同时支持解释式运行 和 基于 LLVM 的编译后运行，以优化性能。

DuckDB 1.4.0 新排序算法(性能爆缸) https://mp.weixin.qq.com/s/h4TAHoNoLI-pZL_W3rKHOw  【`11.9`】
- > 起因是DuckDB在hash join & hash agg中使用的可溢出页面布局方案取得了非常好的效果, 此次重新设计排序也得益于此方案. 下面看看详细设计说明.
- > 以下内容翻译自: https://duckdb.org/2025/09/24/sorting-again.html

【[ :star: ][`*`]】 DuckDB花470亿存了一部电影, 你猜它要干什么？ https://mp.weixin.qq.com/s/vRsAXIsZPOTRuOymamQbPA  【`11.5`】
- > 把电影塞进DuckDB后, 能做什么分析? 这个可能属于影评、营销、导演的专业领域了.
- > 下面就看看DuckDB工程师怎么玩的? 以下内容来自： https://duckdb.org/2025/10/27/movies-in-databases
- > 其实通过这篇文章, 我们还能学习到DuckDB的炫酷特性, 例如 replacement scans、POSITIONAL JOIN、SUMMARIZE、超内存的聚合哈希表 .
- > TL;DR：你可以在 DuckDB 中存储甚至处理视频。在这篇文章中，我们会向你展示如何做到这一点。
- > “你们的科学家太专注于‘能不能做到’，却从未停下来想想‘该不该这么做’。”——伊恩·马尔科姆博士，《侏罗纪公园》（1993）
- > 忽略免责声明
  * > 但把一部电影变成一张表格，会是什么感觉呢？（非常）深入地看，电影不过是一连串快速移动的画面（“帧”），通常每秒约 25 帧。在这个速度下，我们的猴子大脑无法区分单个图像，从而被欺骗以为看到了流畅的动作。顺便提一句，对年轻一代来说，一卷图像胶片正是我们在过去一百多年里分发电影的方式。
  * > 所以，就是一连串图像。每张图像还可以进一步分解为一个二维数组（一个“矩阵”）的点，也就是所谓的“像素”。每个像素又由三个数字组成，分别代表红、绿、蓝的强度，简称 RGB。注意，本文忽略了音轨，但原则上处理方式完全一样，只是强度类型不同。
  * > 但我们还是坚持用一张连 System R 都能处理的表。此外，***显式写出所有偏移量，就不需要依赖模糊的约定或额外的元数据来知道数组数据是按什么轴顺序序列化的***。
- > 实验
  * > 既然我们只是在创建一张表，就会使用 DuckDB 的原生存储格式。以下是我们用来转换电影的 完整 代码片段。事实上，这段代码应该足够通用，可以将任何 ffmpeg 能读取的内容转换为表格。万一你想在家试试自己的电影呢。
    ```py
    import imageio  
    import duckdb  
    # 设置电影读取  
    vid = imageio.get_reader("Charade-1963.mp4", "ffmpeg")  
    dim_x = vid.get_meta_data()['size'][0]  
    dim_y = vid.get_meta_data()['size'][1]  
    rows_per_frame = dim_y * dim_x  
    # 设置 duckdb 数据库和表  
    con = duckdb.connect()  
    con.execute("ATTACH 'charade.duckdb' AS m (STORAGE_VERSION 'latest'); USE m;")  
    con.execute("CREATE TABLE movie (i BIGINT, y USMALLINT, x USMALLINT, r UTINYINT, g UTINYINT, b UTINYINT)")  
    # 这些偏移量在帧之间不变，因此预先计算  
    con.execute("CREATE TEMPORARY TABLE y AS SELECT unnest(list_sort(repeat(range(?), ?))) y", [dim_y, dim_x])  
    con.execute("CREATE TEMPORARY TABLE x AS SELECT unnest(repeat(range(?), ?)) x", [dim_x, dim_y])  
    # 遍历电影中的每一帧并插入像素数据  
    for i_idx, im in enumerate(vid):  
        v = im.flatten()  
        r = v[0:len(v):3]  
        g = v[1:len(v):3]  
        b = v[2:len(v):3]  
        con.execute('''INSERT INTO movie   
            FROM repeat(?, ?) i -- 帧偏移量   
            POSITIONAL JOIN   y -- 临时表  
            POSITIONAL JOIN   x -- 临时表  
            POSITIONAL JOIN   r -- numpy 扫描  
            POSITIONAL JOIN   g -- numpy 扫描  
            POSITIONAL JOIN   b -- numpy 扫描  
            ''', [i_idx, rows_per_frame])  
    ```
  * > 这段脚本不仅用到了一个，而是（至少）两个 很酷的 DuckDB 特性。首先，***我们使用所谓的`“替换扫描”`（`replacement scans`）直接查询 NumPy 数组 r、g 和 b***。注意，***这些数组并没有在 DuckDB 中创建为表，也没有以任何方式注册，但在 INSERT 语句中却通过名称被引用。<ins>这里发生的是，DuckDB 会检查 Python 上下文，寻找缺失的“表”，并找到它能读取的同名对象</ins>***。另一个很酷的特性是 `POSITIONAL JOIN`，***它让我们能按位置将多个表水平拼接，而无需执行实际（昂贵的）JOIN***。这样，我们就能为单帧组装所有需要的列，并以批量 INSERT 的方式高效执行。
  * > 我们使用的电影文件帧率为`每秒 25 帧`，分辨率为 `720x392 像素`（接近 DVD 质量）。总时长为 `01:53:02.56 秒`，共 `169,563 帧`。***由于每像素一行，我们最终得到 `169,563 × 720 × 392 行`，即 `47,857,461,120 行`——`470 亿行`***！终于迎来“大数据”了！然而，当存储为 DuckDB 数据库时，文件大小“仅”约为 `200 GB`。在笔记本电脑上完全可行！
  * > DuckDB 的轻量级压缩在这里表现相当不错。***在一种原生的二进制格式中，我们至少需要为每行存储 `15 字节`。如果乘以行数（记得吗，470 亿），我们会得到大约 `700 GB` 的存储空间***。
  * > 为了证明转换是准确的，我们试着把表中某一随机帧的数据还原成人类可读的图像：从 DuckDB 中检索对应行，并用一些 Python 魔法将其转回 PNG 图像文件：
    ```py
    import duckdb  
    import numpy as np  
    import PIL.Image  
    frame = 48000  
    con = duckdb.connect('charade.duckdb', read_only=True)  
    dim_y, dim_x = con.execute("SELECT max(y) + 1 dim_y, max(x) + 1 dim_x FROM movie WHERE i=0").fetchone()  
    res = con.execute("SELECT r, g, b FROM movie WHERE i = ? ORDER BY y, x", [frame]).fetchnumpy()  
    v = np.zeros(dim_y * dim_x * 3, dtype=np.uint8)  
    v[0:len(v):3] = res['r']  
    v[1:len(v):3] = res['g']  
    v[2:len(v):3] = res['b']  
    img = PIL.Image.fromarray(v.reshape((dim_y, dim_x, 3)))  
    img.save(f'frame.png')  
    ```
  * > ![](https://mmbiz.qpic.cn/sz_mmbiz_png/MEMM7vtMGgOQgQMXL8AyFjbG9ZNHemiaXfsOQMote32Xz0KIqxwIkC4hiaEYzxdIwEialu780MxlcqZnzhDYMy62w/640)
  * > 瞧！一张奥黛丽和加里的精彩画面出现了。这个技巧也可以用来生成一系列图像，并通过 `moviepy` 等库重新写入 MPEG-4 文件。
  * > 但现在我们有了表格，就可以玩点有趣的了。先做一些基本探索：从 DESCRIBE 开始，它基本上告诉我们表的结构。我们当然早就知道这个。
  * > 啊，没错，470 亿。各列的数值特性如何？DuckDB 有个很酷的 `SUMMARIZE` 语句，可以在表（或任意查询）上单次扫描计算汇总统计信息。
  * > 这确实有点炫技了。DuckDB 能在 MacBook 上用大约 `20 分钟`计算出这 `470 亿行`的详细汇总统计。结果如下：
  * > 既然我们本质上存储了大量颜色，那么到底有多少种不同的红、绿、蓝组合呢，DuckDB？
  * > 任何有经验的数据工程师都会合理地警告你不要对这么多行运行 DISTINCT。毕竟太多生产事故都是因为聚合溢出造成的。但得益于 DuckDB 支持超内存的聚合哈希表，我们可以放心地发出这个查询。我们甚至还能看到一个漂亮的进度条，以及（自 1.4.0 起）一个出奇准确的查询耗时预估。
  * > 大约有 80 万种不同的颜色。计算这个花了大约 2 分钟。但这些颜色的频率如何？我们来计算使用最多的 10 种颜色的直方图！
  * > 但我们还能玩得更嗨一点。我们有一个分析型数据库系统。那我们来计算每 1000 帧的平均帧，再把结果拼成一部新电影怎么样？这不过是个大型聚合。我们先创建实际的平均值：
  * > 然后，我们再次使用 Python 将这张 averages 表转换成一部电影：
  * > 这里有些数据整理工作，因为我们希望一次性批量获取整个帧数据集，而不是为每一帧单独查询。然后我们用 NumPy 将它们按帧拆分，并将 RGB 通道拼接成图像库喜欢的三维数组。这没有任何商业用途，但结果还挺有趣。这是第 68 号平均帧，向演员们致歉：![](https://mmbiz.qpic.cn/sz_mmbiz_png/MEMM7vtMGgOQgQMXL8AyFjbG9ZNHemiaXuZr5hPEc0ZKAHl4lkZyBibpFSOgOnu8nJE6aAx5LrbzIvVmr5SbiaDAQ/640)
  * > 我们还可以把所有平均帧拼在一起，制作一部有点抽搐的平均电影：
  * > 再加点乐趣，我们甚至可以写一个 SQL 查询，把一帧变成一个每个单元格只有一像素的 HTML 表格。下面是结果，希望你的浏览器能渲染它，并再次感谢 Cloudflare 赞助我们的流量。下面是这个有点亵渎神明的查询：
- > 结论
  * > 你可能已经看出来，这篇文章并不完全严肃。我们玩得很开心。但我们学到了什么？几点：首先，基本上任何东西都可以表示为一张表格，哪怕是一部冷门的 1966 年电影。从宏观角度看，这可能不是个好主意——有像 ffmpeg 这样出色的开源库和像 VLC 这样的应用来处理电影文件，或者同样地处理它们的“数组表亲”——音乐或图像。尽管数据量暴增、行数达到数十亿，DuckDB 实际上处理得相当不错，无论是它的数据格式还是执行引擎。在 DuckDB 团队，我们的使命是提升你处理各种形态和规模数据的整体信心，希望这篇文章对此有所贡献。最后，别忘了注意你的版权声明！

PG 冷热分离案例 | 把JSON存入S3 Parquet https://mp.weixin.qq.com/s/8DUVxHo6VBZ8E0eh8XhlIw  【`11.4`】
- > 下面是一篇实践文章. 内容翻译自:  https://www.shayon.dev/post/2025/276/exploring-postgresql-to-parquet-archival-for-json-data-with-s3-range-reads/
- > 这是一篇熟悉 Parquet 的好文章： https://arrow.apache.org/blog/2022/12/26/querying-parquet-with-millisecond-latency/ 或: 《数据库筑基课 - 列存之 Parquet》

使用GDB和VS Code调试PostgreSQL实操 https://mp.weixin.qq.com/s/Ex79eMe8b9UwmVbiXHrVhQ  【`11.3`】
- > 以下内容翻译自: https://sbaziotis.com/databases/building-and-debugging-postgres.html

天翼云开源TeleDB！为什么？ https://mp.weixin.qq.com/s/RNyMQWp64qMRVDMVFU7zwQ

比鸭数据库(DuckDB)快10倍, 狼数据库(Sirius)诞生! https://mp.weixin.qq.com/s/NfCerxclF9WRSCf9lQmDpA  【`11.2`】
- > Sirius 是一个GPU 原生 SQL 引擎（GPU-native SQL engine）。号称比DuckDB快10倍, 比ClickHouse快60倍. ( 在 TPC-H SF=100（Scale Factor = 100）基准测试中，Sirius 在相同硬件租赁成本下，相比现有 CPU 查询引擎实现了约 10 倍的加速，非常适合用于交互式分析（interactive analytics）、金融工作负载（financial workloads）和 ETL 任务（ETL jobs）。 )
- > 这不禁让我想到了另一个PG的GPU数据库插件, 不知道现在怎么样了, 刚看了一眼github, 更新还很频繁, 希望能持续活下去:
  * > https://github.com/heterodb/pg-strom
- > 还可以通过标准的 `Substrait` 查询格式（Substrait query format）无缝集成到现有数据库（如 DuckDB）中，无需重写查询语句或对系统进行重大改造。无需改变你的技术栈即可获得性能提升, 就问你爽不爽!
- > 架构如下: ![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/MEMM7vtMGgMMfRuObQIicoU2Ve0eBarmkPvbEbicQTy3tibvz4FNpsC4LsQ4r3ibBjroNB9Tx2MHcjc3scqpuaAD8w/640)
- 回复：
  * > 用 TPCDS 测试集测了下 duckDB 复杂查询的性能，真是吓人。现在又来一个小天狼星……
    >> 是不是简直快到怀疑人生崩溃
    >>> 是

# 10

PostgreSQL postmaster代码深入探究, 从启动到关闭的逻辑 https://mp.weixin.qq.com/s/eW6JBANy_31abUNstFBr8A  【`10.31`】

某教授批评“学术圈已空心化，论文是文字垃圾” 这20篇TOP数据库论文还有读的必要吗？ https://mp.weixin.qq.com/s/oi_sFxAKs0nNGk8-BfrtZw  【`10.30`】
- > 作者 Ryan Marcus，宾夕法尼亚大学计算机科学系助理教授。作者正在利用机器学习构建下一代数据管理工具，这些工具能够自动适应新硬件和用户工作负载、发明新颖的处理策略，并理解用户意图。
- > 下面是一篇他的文章: https://rmarcus.info/blog/2025/03/28/hottest-db-topics.html
- > 学习型索引（Learned Indexes）
  * > 自从 Tim Kraska（在谷歌休假期间完成该工作，随后从布朗大学转至麻省理工学院）发表关于学习型索引的论文以来，数据库社区一直在积极开发新的学习型索引、对其进行基准测试，并将其集成到实际系统中。普渡大学最近的一篇综述论文清晰地展示了这一领域的爆炸式增长：![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/MEMM7vtMGgMzIHjo3XRTJhIvVXfyuej813ogFm36plibWvfT2EFVhfTNpicGA9kP3FeJql3f4pWLMTNWKjWsTnvw/640)
    >> 【[ :star: ][`*`]】 //notes：这个图真的卷。。。
  * > 据我所知，《ALEX》是第一篇实现可更新学习型索引的论文，它利用了一种自适应树结构。第一作者 Jialin Ding 当时是 Kraska 实验室的博士生，如今已是普林斯顿大学的教员。Jialin 还是另一篇论文的主要作者，该论文描述了如何将多维学习型索引集成到 AWS Redshift 中。
  * > Kraska 的论文最初引发轰动已有一段时间了，但作为一篇 SIGMOD 论文，它当时颇具争议。网上充斥着各种讨论：我们是否该扔掉算法教科书？ 还是继续用 B-Tree？ 在我看来，部分混乱源于原始 SIGMOD 论文并未附带代码。如果你不相信某个想法，很容易随手写出一个糟糕的实现。幸运的是，自 2018 年以来，我们对学习型索引为何有效已经有了更清晰的理解。
- > （学习型）查询优化（(Learned) Query Optimization）
  * > 可以说，自 2001 年 IBM 的 LEO 论文以来，我们一直在尝试构建能从错误中学习的查询优化器。毕竟，如果优化器选了一个糟糕的查询计划，为什么下次不能选个更好的呢？
  * > 数据库社区至少从三个方向攻克这个问题，而这些方向在“最热门”论文中均有体现：
    ```
    使用机器学习方法（如深度学习）替代基数估计；
    使用半监督或引导式学习技术替代代价模型；
    使用强化学习来替代或引导整个查询优化过程。
    ```
  * > 尽管学术界仍在热情洋溢地争论各种方法的优劣，工业界也在学习型查询优化方面取得了一些进展，包括：
    ```
    微软和 Meta 部署了“引导式”优化器；
    AWS Redshift 的智能扩缩容和工作负载管理器中集成了学习型性能预测器。
    ```
  * > 经典论文`《查询优化器到底有多好？》`(`How Good Are Query Optimizers, Really?`) 也榜上有名，因为“联接顺序基准”（join order benchmark, JOB）如今已成为查询优化研究中的标准测试集。当然，这篇论文本身也是查询优化领域的奠基之作！
- > 数据库管理系统引擎（DBMS Engines）
  * > 《Spark SQL：Spark 中的关系型数据处理》（`Spark SQL: Relational Data Processing in Spark`）
  * > 《Snowflake 弹性数据仓库》（`The Snowflake Elastic Data Warehouse`）
  * > 《Amazon Aurora：面向高吞吐量云原生关系数据库的设计考量》（`Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases`）
  * > 《DuckDB：一个可嵌入的分析型数据库》（`DuckDB: an Embeddable Analytical Database`）
  * > 在我看来，最值得注意的近期成果是 DuckDB。长期以来，向量化、支持外存（out-of-core）的分析型数据库要么是专有产品（如 Vertica），要么深藏于慕尼黑工业大学的代码仓库中（如 Hyper，后被 Tableau 收购，再转至 Salesforce）。而 DuckDB 不仅提供了最先进的向量化数据库实现，还将其打包为一个易于使用的嵌入式工具。因此，DuckDB 已成为实现新型 OLAP 技术（如新式连接顺序优化或机密计算）的事实标准试验平台。
- > 机器学习驱动的系统调优（ML-powered System Tuning）
  * > 数据库有无数“旋钮”（knobs）。无论是经典的 PostgreSQL shared_buffers，还是更冷门的 Vertica 资源池配置，为你的工作负载设置合适的参数始终是性能调优的关键步骤。

PG 18 AIO 性能改进详细评测 https://mp.weixin.qq.com/s/ljcLAS3uhWinEjlsZrMUyw

PostgreSQL 19 preview - group by all https://mp.weixin.qq.com/s/6MuGqIrtoD_0NY55m9Y9kw  【`10.16 17:30`】
- > PostgreSQL 19 将新增 `group by all` 的分组聚合语法alias, 在select子句中的所有不带聚合函数、窗口函数的选择列都会被作为group by子句. 方便简化SQL书写内容.

国人提交PG 19“JOIN+聚合场景”优化补丁 https://mp.weixin.qq.com/s/FsWM8vf0UiMb9cOEvHTGeg  【`10.16 06:00`】
- > 前几天读到一篇关于"先groupby再JOIN"的数据库论文:`《AI论文解读 | Accelerating Queries With Groupby And Join By Group Join》`没想到今天在PG社区就看到类似场景的优化补丁了: `Implement Eager Aggregation`
- > 下面来看一下这个patch的详细解读:
- > 这个 PostgreSQL 补丁 `“Implement Eager Aggregation”`（实现`“急切聚合”`）由 Richard Guo 提交，是对查询优化器的一项重要增强。它引入了一种称为 `Eager Aggregation（急切聚合）` 的优化技术，旨在通过在连接（JOIN）之前提前执行部分聚合，减少中间数据量，从而提升查询性能。

PostgreSQL C 插件开发与打包指南 https://mp.weixin.qq.com/s/HdcxDujBrd4bb6udWTa0hQ  【`10.14`】
- > 但是开发插件的流程最好先熟悉一下, 下面就翻译一篇 `<Postgres扩展开发简介>` 的文章 https://www.pgedge.com/blog/introduction-to-postgres-extension-development

AIO 是PostgreSQL的终点吗? 不, 未来将大力发展DIO https://mp.weixin.qq.com/s/BwbnPyA18tuBhJSiCmWhpg  【`10.9`】

# 09

Mooncake脱胎换骨，九阳神功初成 https://mp.weixin.qq.com/s/1C2jX_nUw7ZZ7KdScoxZKw  【`9.24`】
- > Mooncake脱胎换骨，九阳神功初成
  * > HTAP? 哦这个就是解决以上ETL问题的解决方案之一, ***通常是在OLTP数据库中提供列存储引擎、列索引的方式, 在数据库内部将行存表异步转换为列存表或增加列式索引, 提供分析能力***. 但是这个解决方案仅限于当前数据库实例, 如果是跨实例怎么办呢? 还得入湖或入仓.
  * > 简单理解一下 `moonlink` 核心功能包括
    + > 实时将上游数据源(pg、kafka、events、rest api)等产生的dml生成内部缓存(***可能是arrow格式, 面向读优化***), 并异步合并到iceberg(增量parquet文件及vectors文件(包含delete数据ID)).
    + > metadata管理
  * > 另外配合 moonlink 使用的模块包括
    + > `pg_mooncake`(PG的插件) , 在PG中查询 moonlink(实时部分) + iceberg(异步部分) 的数据, 并使用duckdb计算引擎提速.
    + > `duckdb_mooncake`(DuckDB的插件) , 在duckdb中查询 moonlink(实时部分) + iceberg(异步部分) 的数据.
    + > datafusion mooncake(datafusion的插件) , 在datafusion中查询 moonlink(实时部分) + iceberg(异步部分) 的数据.
  * > Mooncake-Labs 在做的事情是打通oltp和数据湖, 给oltp数据库插上“实时同步”的翅膀和“实时分析”的翅膀.
  * > 让我们来看看moonlink的项目文档: 以下翻译自 readme.md

Supabase 宣布: OrioleDB 真.Free https://mp.weixin.qq.com/s/hHCJaEwn3zuWRqoUgHtgzQ  【`9.23`】
- > 如何参与
  ```sh
  docker run -d --name orioledb -p 5432:5432 orioledb/orioledb  
  ```

【[ :star: ][`*`]】 PostgreSQL 性能优化依赖这些配置 https://mp.weixin.qq.com/s/0J_b0EnIw2WMngoZcZeyxg  【`9.4`】
- > 数据库性能优化, 没有日志可不行.这篇文章介绍了很多常用以及不常用的日志参数, 算是性能优化相关的日志参数入门科普大荟萃吧.
- > 以下内容翻译自: https://www.crunchydata.com/blog/postgres-logging-for-performance-optimization

OLTP LakeHouse 架构千篇一律，毫无创意 https://mp.weixin.qq.com/s/W-9k_jpG3_mYaMaOa6aesw  【`9.1`】

# 08

Postgresql极限救援！48小时恢复1.5TB生产数据 https://mp.weixin.qq.com/s/QK4tSnSPFP8skqdeC-7Ccg  【`8.31`】
- > `PDU`注定是为特殊场景而生的，一个月前，我终于等到了这个特殊场景的到来，十分骄傲地在此给各位分享。
- > **客户场景**
  * > 数据量为 1.5TB  的Postgresql数据库，版本为16.7，且包含Postgis 3.2.8版本的空间数据。
  * > 现场问题为磁盘坏块导致数据字典损坏，数据库已无法打开，且备份也无法使用。

VectorChord重磅发布: 支持图(DiskANN和HNSW)索引、召回率评估 https://mp.weixin.qq.com/s/-A81jd6mXDcxidlLyFP8Hg  【`8.27`】
- > VectorChord 更新了, 这次更新迎来了2个大特性:
  * > 基于图(DiskANN和HNSW)的索引, 索引可超越内存大小
  * > 内置召回率评估函数
- > 如果你还不太了解VectorChord, 也可以先翻一翻我之前写的文章
  * > 《VectorChord 向量插件学习心得》
  * > 《向量插件新贵 VectorChord(IVF+ RaBitQ量化), pgvector 和 milvus 都被秒杀了》

PG实时堆栈跟踪 https://mp.weixin.qq.com/s/Gwyh0DskEd0jhmlp-922pQ  【`8.22`】

PostgreSQL 逻辑复制会不会被多次消费？ https://mp.weixin.qq.com/s/lOi3AaAgOO19oiiIVgW9gQ  【`8.20`】

绝不吹牛! 用DuckDB 超速完成机器学习数据预处理任务 https://mp.weixin.qq.com/s/huWgW2Fk-fU7sLhOEGsDmw  【`8.18`】
- > 不吹牛, 没有测试场景偏颇, 凭借向量化提供优异的性能表现、SQL语法糖提供简洁的写法、进程级能力避免数据搬用, 作为机器学习训练之前的数据预处理任务(数值化特征编码: 独热编码、顺序编码、标签编码, 特征缩放/归一化: 标准缩放、最小-最大缩放、稳定缩放等, 缺失值处理等), 相比于scikit-learn, 最终DuckDB大获全胜.数据量越大, DuckDB优势越明显.
- > 以下翻译自原文: https://duckdb.org/2025/08/15/ml-data-preprocessing.html

围观博主“吹牛”被啪啪打脸，你说该不该打？ https://mp.weixin.qq.com/s/Y4zYHBJDd2JswKe22Ng-UA  【`8.15`】
- > DuckDB Spatial 傲视群雄？
  * > PostGIS专家梅老师提到spatial join里的示例不够典型, 大量位置为同一个点, 性能提升打擦边球了.（梅老师是GIS老司机，以后大家有问题可以来群里找他）
  * > DuckDB ST_DWithin和ST_Intersects等价用法的结果不一致, 说明DuckDB spatial插件还不能用于生产.
  * > 详见：
    + > [PostGIS霸主地位不保？PostGIS vs DuckDB空间分析性能实测](https://mp.weixin.qq.com/s/ApR8DFoBNApiycKn9IDJdg)
    + > [GIS空间分析场景DuckDB Spatial真比PostGIS快？](https://mp.weixin.qq.com/s/f8xM8h7sz0HZnzR1dAclFw)
  * > 梅老师测试数据集( 可到这里找: https://github.com/digoal/blog/blob/master/202508/20250811_01.md ): gis data: 20250811_01_data_001.zip

国人用Rust手撸DuckDB Excel插件丝般柔滑 https://mp.weixin.qq.com/s/n1WPRYJcqPTUTJAQ3FQQJQ  【`8.14`】
- > 用DuckDB分析excel里的数据是非常常见的操作, 所以excel也是DuckDB插件里的一等公民(内置核心插件之一).
- > 但是不管你使用excel插件还是spatial插件里gdal自带的st_read读excel数据总是有一些不尽人意的地方.
- > 例如中文编码、sheet支持、excel内容解析、访问远端excel(如对象存储)、异常数据处理不完善等. 都不如DuckDB读取csv文件这么丝滑.

PostGIS霸主地位不保! DuckDB SPATIAL 400倍性能傲视群雄 https://mp.weixin.qq.com/s/M0Ff9ZY-F4WcDwO0VtmMzg  【`8.13`】
- > 正式开始前，插一句，我找GIS专家用本文同样的数据集测过`PostGIS`了（含空间索引），结果拿不出手。
- > 自从DuckDB推出`spatial插件`以来, 经过不断优化, PostGIS霸主地位正在被撼动, 我们先拿GIS应用里最为常见的空间分析为例.
- > 多边形 join 多边形/轨迹/点 通常出现在空间统计分析中, 例如 想找出人流量大的热门街区、出租车早上最热门的起点和终点 ...
- > 这些都需要大量轨迹数据 JOIN 大量行政区块(甚至细到小区/写字楼), PostGIS里只能使用nestloop join来完成此操作, 非常非常耗时.
- > `DuckDB spatial扩展插件`类似JOIN操作是如何做到400倍性能提升的?
- > 核心是DuckDB提供了一个新的JOIN算子: `SPATIAL_JOIN`
- > 除了常见的hash join , merge join , nestloop join. SPATIAL_JOIN 是什么鬼? 如何实现了空间运算的并行HASH JOIN类似效果.
- > 别急, 往下看, 以下内容翻译自: https://duckdb.org/2025/08/08/spatial-joins.html

如何统计每个PG进程的真实内存消耗? https://mp.weixin.qq.com/s/Z9bpac-WJb3qfjA-YUAzew  【`8.12`】
- > PG是进程模型的数据库, 如何统计每个进程的内存开销? 例如你想进行精确的内存控制?
- > 可以看看这个插件 https://github.com/bonesmoses/pg_meminfo
- > `pg_meminfo` 插件可以统计PostgreSQL每个进程的内存消耗, 数据来源为Linux操作系统对每个PID的`smaps`的统计信息, 所以目前这个插件仅支持Linux下的PostgreSQL, 如果是其他操作系统恐怕要先阅读一下相关的系统文档, 看看有没有类似的统计信息可获取.

生成PG内部元数据对象关系图的小工具 https://mp.weixin.qq.com/s/kzFAamChAqHh5R3HD3xeFg  【`8.8`】
- > pdot 这个开源的小工具有点意思, 可以用来生成PostgreSQL元数据(例如表、视图、索引、触发器等)的关系图. 格式支持mermaid、GraphViz dot.
- > https://gitlab.com/dmfay/pdot
- > 如果能将这个功能整合到开发者的IDE工具(如pgAdmin), 或者DBA的日常维护工具(例如云数据库服务的类似DMS的产品)中, 使用起来就更方便, 价值就更大了.下面是几个截图可以感受一下

DuckPGQ 论文详解 https://mp.weixin.qq.com/s/KKU3tdTyxyCsoNLnrMxuYw  【`8.7`】

单车变摩托 | PG + SQLite = 嵌入式PG https://mp.weixin.qq.com/s/BkIJLPwa1GJ1-mJZ3pC0bw

这个赛道没戏了｜DuckDB 正式发布PGQ，附详细使用说明 https://mp.weixin.qq.com/s/WxCHt02D9FmyF51-1k5Z8Q  【`8.1`】

# 07

图数据库搅局者｜每秒处理数十亿条边 https://mp.weixin.qq.com/s/VKC4h9oqlNj_I1FDxtKD8g  【`7.30`】

存算分离架构软肋｜云盘性能不行 https://mp.weixin.qq.com/s/7bk2PmDLjnBXS6CE_mTjqQ  【`7.29`】

海外PG厂商互殴｜PlanetScale “作弊”测试引公愤 https://mp.weixin.qq.com/s/qesHyqit3Zu4r1chS6CM9Q  【`7.28`】
- > PlanetScale 引起公愤, 如今战火已蔓延到了另外几家知名PG系厂商(OrioleDB, Neon, Xata):
  * https://www.orioledb.com/blog/orioledb-beta12-benchmarks
  * https://neon.com/blog/separation-of-storage-and-compute-perf
  * https://xata.io/blog/reaction-to-the-planetscale-postgresql-benchmarks

阿里云放大招｜RDMA过时了！你信吗？ https://mp.weixin.qq.com/s/7G6pzUV_xEzOB05t8-mOsQ  【`7.21`】

为什么DuckDB运算数据量可以超过内存？ https://mp.weixin.qq.com/s/BJe4MNsksXCzEtnOor44Ig  【`7.20`】
- > 原文: https://duckdb.org/2024/07/09/memory-management.html

违法了｜某国产数据库安装TimescaleDB插件要价20万 https://mp.weixin.qq.com/s/Ky-6qVrLFwPT-VPSN3fnKA  【`7.17`】
- 回复：
  * > 斗胆问下是opengauss吗？
    >> 不知道，期待勇士的继续爆料
  * > 某国产pg换皮数据库（排名靠前)，禁止安装开源插件，但自己换名白名单的可以装（功能一样的，你懂的），结果自己家换皮的两款插件之间还冲突导致同步异常。是TM真国产，不坑外国人。

DuckDB论文解读 | DuckDB: an Embeddable Analytical Database https://mp.weixin.qq.com/s/_7-3y6L1aylhYBkHu3VZPA  【`7.16`】

所有的“遥遥领先”都经不起推敲 https://mp.weixin.qq.com/s/gKUxrf6E_gcLc99rFzek7A  【`7.15`】
- > 看对比数据, 似乎PlanetScale吊打了几乎所有主流云厂商的PG服务!
- > PlanetScale 是一个基于 Vitess 开源项目的 无服务器（Serverless）MySQL 数据库即服务（DBaaS）平台，由 Vitess 的共同创造者和维护者于 2018 年创立，总部位于美国加利福尼亚州山景城。它专注于为开发者提供高性能、可扩展且兼容 MySQL 的云数据库解决方案，并引入了类似 Git 的分支管理功能，使数据库开发和管理更加灵活。
- > **秘密就是本地存储**.被对比的PG 云服务产品都采用了云盘. 而PlanetScale 是本地存储. 

【[ :star: ][`*`]】 无需安装 | 浏览器内直接运行PostgreSQL https://mp.weixin.qq.com/s/eBC_evG1lQD6VmM3UTGZNg  【`7.10`】
- > 好了现在终于可以在浏览器中体验PostgreSQL了, 就像之前我们说的体验 DuckDB/glaredb 那么简单
  * > https://shell.duckdb.org/
  * > https://glaredb.com/
- > 感谢PGLite, 把PostgreSQL进行了WASM封装, 点开下面的URL即可使用。PGlite can be used in both Node/Bun/Deno or the browser, and with any JavaScript framework.
  * > https://pglite.dev/repl/
- > 或者你也可以使用 `pigsty` ( https://pigsty.cc/  ,  https://pigsty.io/ ) 直接拉起pg进行学习.
- > 更多PGLite REPL的用法请参考:  https://pglite.dev/docs/
- 回复：
  * > 浏览器wasm限制太多了 32位地址空间 最多只有4G的寻址空间 也就是4G内存 还没法持久化 wasm感觉除了做插件 没什么用😢

# 06

无法反驳｜这个点MySQL真完败PG https://mp.weixin.qq.com/s/4uKI4aMEQvNz1W5NA7evhQ
- > 下面2张图是来挑事的，MySQL认证安全完败PG(特指md5).
- > **1、PG md5**
  * > ![](https://mmbiz.qpic.cn/sz_mmbiz_png/MEMM7vtMGgMIMVqKiaBqKomPs97VH4t18wtwfiaKaz9BKTnocicJJkwlQanIibuvCncSOZeIHCrdu1qC7AjpttwvqQ/640)

千万别让甲方知道这个｜比DuckDB还快10倍！压测必备 https://mp.weixin.qq.com/s/7mz4qCiYtt7UnY3B-Wl4RQ

DuckDB进军DB4AI｜“语义(向量)搜索、全文检索、BM25、模糊检索”一网打尽 https://mp.weixin.qq.com/s/RZ_YY3JeIO5vvIsppumJEg
- 回复：
  * > duckDB用一句话总结的话，就是写不进，存不下，算不准
    >> 这话简直给DuckDB判了死刑，会不会太武断了。毕竟30K的star了，需要多给证据才好说明问题。
    >>> 用过或只是写文章，是不同的
    >>>> 是的,深入用和浅尝能得出完全不同的结论.
    >>>>> 信创无处不在
  * > DuckDB唯一缺点，不太健壮，一天死九回
    >> 怎么死的说说，是不是内存配置不当OOM了？
    >>> 从数据入库到计算存储，常规的BUG频出不穷
    >>>> 几个例子，列存中的PK，高频插入时一天无故报错几回；内存管理，特别是读写外部数据源时，内存狂泄不止；***SQL算子一致进，非一致出，计算结果不一致是常态***。真玩过的自然懂。
    >>>>> 就目前而言，duckDB仍是一玩具。不再发了，直接建议关闭下架，别坑人。国外信创真品，无解。
    >>>>>> 如果真的发现了这么多问题，建议可以整理出复现方法，让社区可以尽快修复。
    >>>>>>> 不支持并发插入或更新。检索转或换数据还是可以的。[得意]

震惊｜DuckDB疑被某Rust项目“抄袭” https://mp.weixin.qq.com/s/u0Eae_-2O6fXvCVYoUosMA
- > 和PostgreSQL/MySQL有大量的追随者一样, DuckDB也迎来了第一波“抄袭者”: `GlareDB` (Rust项目), 一样很小巧, 一样性能杠杠的! 
- > 实际上GlareDB并不是“抄袭者”, GlareDB 是采用了DataFusion技术栈的产品.
- > DataFusion是Rust编写的, 将数据库拆成不同功能模块的多个开源项目, 包括交互协议、SQL解析优化执行器、存储、事务管理等, 是面向大数据的技术栈集合.
- > 我之前写过一篇文章介绍DataFusion《将 "数据结构、数据存储" 从 "数据库管理系统" 剥离后 - 造就了大量大数据产品(DataFusion, arrow-rs, databend等)》 https://github.com/digoal/blog/tree/master/202303/20230328_02.md

某国产数据库研发被洗脑，坚称“PG比MySQL快不符合预期” https://mp.weixin.qq.com/s/WJuNa2AIWtrkmRw-xkHcbw

Snowflake收购PostgreSQL商业发型版Crunchy Data扩大AI Data Cloud版图 https://mp.weixin.qq.com/s/92i_4TaoRRLEH9WBIbQwdg
- > 大手笔和Databricks如出一辙：[赚大了！Databricks 10亿美元买下开源数据库Neon Database](https://mp.weixin.qq.com/s/cHHKAExWHM22mu2RjpTCNQ)
  * > 以上文章介绍了Neon是什么，还漏了一个核心关键信息，其中创始团队包括了PG社区`heikki`，***他就是曾经仅凭一人之力把Greenplum升级到PG 9的男人***，对PG太熟悉了。
- > CrunchyData也不弱啊，初代PG内核之神`Tom Lane`就在这家公司，他就是那个无数年轻人的噩梦，曾把无数PG feat 代码拦在门外。

# 05

DuckDB 存储探秘 之 读时优化 https://mp.weixin.qq.com/s/PMIcMl_FTpJgV0yHpjxU_Q
- > DuckDB 读时优化: 排序 & 部分读取功能
  * > DuckDB 内置数据文件与parquet格式类似, 参考: 数据库筑基课 - 列存之 Parquet, 采用列存储, 同时也支持rowgroup, 每个rowgroup头部都有对应元数据信息记录该组的min/max值等. 更多细节见DuckDB源代码. 
  * > 本文提到了DuckDB 的读时优化, 实际上就是写入数据文件时: 尽量批量排序写入, 以及如何选择排序字段? 如何设置rowgroup大小?  使得DuckDB读时根据过滤条件和metadata快速跳过不需要访问的rowgroup提高读时性能.  这有赖于DuckDB的“部分读取”功能.

再见分布式湖仓一体, 你好DuckLake https://mp.weixin.qq.com/s/02JnoIZGgxVbxK9zCvGrmw
- > 下面细看DuckDB推文： https://duckdb.org/2025/05/27/ducklake.html 
- > 产品官网 https://ducklake.select/ 
- > 开源项目(MIT开源协议)地址: https://github.com/duckdb/ducklake

DuckDB出手，图数据库赛道将不复存在 https://mp.weixin.qq.com/s/KRQr8dno9cOml_TaygbcVg
- > 迭代：递归 CTE
  * > 为了增强 SQL 的表达能力， `SQL:1999` 标准中引入了递归 CTE。这些 CTE 允许查询引用同一表达式中先前迭代的结果，从而使 SQL 能够解决更复杂的问题，例如图遍历和其他迭代计算。
  * > 此功能使 SQL 超越了基本的数据检索，允许直接在 SQL 中制定复杂的迭代逻辑。事实上，递归 CTE 使 SQL 具有图灵完备性，这意味着它在理论上可以表达任何计算（只要有足够的时间和内存）。
  * > 递归 CTE 在 DuckDB 中是如何工作的呢？

# 04

MySQL将保持平庸 https://mp.weixin.qq.com/s/QnfCqVOsSxsnjfUZv9UPsg
- > 请点击阅读奇哥的深度评论文章：`《MySQL 的创新版正在逐渐失去它的意义（V9.3的release note读后感）》`
- > 我想知道的是why? MySQL是否会保持平庸? 我甚至非常担心MySQL会从此停更, 我对企业开源产品停更的原因有过一个简单的分享, 文章如下: `《又一开源数据库项目停更！企业开源不能持久的原因是什么？》`

MySQL出息了! 大败PG用的这个case https://mp.weixin.qq.com/s/XL_319dq6-Edphxgq0KnrQ
- 有图有真相，MySQL性能是PG的360倍，DS还建议抛弃PG https://mp.weixin.qq.com/s/mQiId_jw4q0ad2EEDNOzeg

14以来最值得期待的版本: PostgreSQL 18 https://mp.weixin.qq.com/s/o13a6_pkMRNaCqQ7h2A4Hg
- > 从PostgreSQL 10开始, 我养成了一个习惯, 在 git.postgresql.org 和 https://commitfest.postgresql.org/ 实时跟踪解读PostgreSQL新版本新增的用户相关patch和feat. 从我的blog可以看到10-18这些版本的文章数, 也间接反映了对应版本有多少用户关心的特性.
- > 从历史来看14最牛, 我发了145篇preview. 后面PG开始挤牙膏(过去这么多年回过去看, ***实则15到17这些版本主要在打磨逻辑复制***, 还有一些不够塞牙缝的小功能/体验升级.).

OrioleDB, 更好的PostgreSQL TAM(存储引擎) https://mp.weixin.qq.com/s/TfkctW93QU3P71aFLabmDg
- > OrioleDB正在开发一种新的表访问方法(`Table Access Method`, `TAM`)，旨在解决PostgreSQL现有heap访问方法的一些根本性限制。PostgreSQL HEAP 表引擎最需要的功能是：
  * > 1 替代的 MVCC 实现，例如基于 UNDO 日志的存储。提供此功能的动机在Uber 博客文章、Andy Pavlo 博客文章和许多其他来源中得到了充分讨论。还有来自digoal的 `《DB吐槽大会,第1期 - PG MVCC》`  虽然digoal以前也力挺PG: `《为PostgreSQL讨说法 - 浅析《UBER ENGINEERING SWITCHED FROM POSTGRES TO MYSQL》》`
  * > 2 非堆式存储。例如，在索引组织表中，索引不是表的可选附加功能（可加快请求速度），而是表存储内部使用的必要层。因此，表元组是复杂数据结构的一部分，不能通过页码和偏移量号等固定长度的地址来寻址。它需要通过索引键等可变长度的标识符来寻址。
- > **原文**
  * > https://www.orioledb.com/blog/better-table-access-methods
  * > 长期以来，PostgreSQL 一直拥有一个可扩展的索引访问方法 API（称为 `AM`），它经受住了时间的考验，并允许许多强大的扩展提供自己的索引类型。例如：rum、pgvector、bloom、zombodb等。`PostgreSQL 12` 引入了 `Table AM` API，承诺为表访问方法提供同等的灵活性。
  * > 尽管 PostgreSQL 的 Table AM API 从版本 12 开始就可用，并且其内置存储引擎（特别是 MVCC 模型）不断受到批评，但令人惊讶的是，还没有功能齐全的事务存储引擎纯粹作为扩展出现。
  * > 由于Table AM 和Index AM API 紧密耦合，因此这对于两种实现来说都是一个问题。
  * > 替代 PostgreSQL HEAP 表引擎最需要的功能是：
    + > 1 替代的 MVCC 实现，例如基于 UNDO 日志的存储。提供此功能的动机在Uber 博客文章、Andy Pavlo 博客文章和许多其他来源中得到了充分讨论。还有来自digoal的 《DB吐槽大会,第1期 - PG MVCC》  虽然digoal以前也力挺PG: 《为PostgreSQL讨说法 - 浅析《UBER ENGINEERING SWITCHED FROM POSTGRES TO MYSQL》》
    + > 2 非堆式存储。例如，在索引组织表中，索引不是表的可选附加功能（可加快请求速度），而是表存储内部使用的必要层。因此，表元组是复杂数据结构的一部分，不能通过页码和偏移量号等固定长度的地址来寻址。它需要通过索引键等可变长度的标识符来寻址。

# 03

PolarDB内核学习 - parser SQL解析器 https://mp.weixin.qq.com/s/A3PmvHFUnj9hnpZC90HD0Q  【`3.21`】

DuckDB 支持 Parquet 布隆过滤器性能飙升 https://mp.weixin.qq.com/s/7cTKlBBCKl6AfObZgJvSnw  【`3.19`】

3分钟上手体验OceanBase https://mp.weixin.qq.com/s/0KMhixyKwhz3oN88qQO7Vw

解读PolarDB PostgreSQL postmaster入口代码 https://mp.weixin.qq.com/s/vZjFVkxybIou8rgX4kRXjw  【`3.12`】

进阶课 11 激活Standby https://mp.weixin.qq.com/s/zYvtA-N2p2Uoc2BVw-4_JA

解读PolarDB PostgreSQL入口点代码main.c https://mp.weixin.qq.com/s/qOw_wX2WgfXON2E803VK-g

PostgreSQL 18 preview - 奇慢无比的GIN索引创建支持并行了 https://mp.weixin.qq.com/s/jT3Mh7Aifdp-pgKNf_y2bg

如果老板提出无理要求, 你会怎么应付? https://mp.weixin.qq.com/s/HWTOft6CENAEKSYVB2MZVQ
- > 为了生计, 我怎么可能被迫答应老板的无理要求: 把PostgreSQL迁移到MySQL. MySQL有啥好的, 虽然老板很喜欢没得办法, 没办法咋个弄? 弄个pi. 
- > 找来找去, 终于找到了前阿里云数据库产品事业部负责人佛爷和普爷公司的产品`NineData`. **居然推出了社区免费版, 这是为老板请来的救兵吧, 太明显了**. 

进阶课 10 灾难恢复 https://mp.weixin.qq.com/s/VcJAZci2qGXxpuHk1Po9sA

进阶课 9 读写分离 https://mp.weixin.qq.com/s/znsgGaR5Te1pEOtLZTqvJg

进阶课 8 时间点恢复(PITR) https://mp.weixin.qq.com/s/Sc1LqggLKrdoM4AVKH-HGA

# 02

数据库筑基课 - 列存之 Arrow https://mp.weixin.qq.com/s/AGBVynV8iWVldSvfzeJXJA
- > **二、Arrow 是什么？**
  * > 例如`pg_strom`插件, 通过arrow打通各个数据库产品数据共享, 打破数据孤岛
- > **四、Arrow 和 Parquet/ORC 是什么关系？**
  * > ***Parquet/ORC同样是采用列存，但是都是面向磁盘设计的，Arrow面向内存设计***
- > **五、支持Arrow的应用**
  * > DuckDB, DataFusion, PostgreSQL 插件、Pandas、Apache Spark、Apache Drill、Apache Flink、TensorFlow / PyTorch、ClickHouse 等.

DuckDB接入DeepSeek https://mp.weixin.qq.com/s/1eYIiiKnrxxyahcef9IbrA

Valgrind - 数据库内核的内存卫士与性能分析大师 https://mp.weixin.qq.com/s/2cXMYI2bxc83ppPt5B8_kg

PostgreSQL 18 支持虚拟生成列（Virtual Generated Columns） https://mp.weixin.qq.com/s/njB2f1fmxV2w3QkTtGxURA
- > 这个 patch 为 PostgreSQL 引入了虚拟生成列（Virtual Generated Columns）的功能。与现有的存储生成列（Stored Generated Columns）不同，虚拟生成列在读取时计算（类似于视图），而不是在写入时计算（类似于物化视图）。虚拟生成列的语法为：
  ```sql
  ... GENERATED ALWAYS AS (...) VIRTUAL
  ```

pg_mooncake VS CrunchyData https://mp.weixin.qq.com/s/KT9oRmgNuBVRNYlXbtub8A
- > 1、CrunchyData . Incremental Archival from Postgres to Parquet for Analytics https://www.crunchydata.com/blog/incremental-archival-from-postgres-to-parquet-for-analytics
- > 2、pg_mooncake v0.2 roadmap 提到, columnstore 将采用logical replication同步数据到parquet, 但是为了提高性能会使用本地行存储缓冲逻辑增量, 达到一定数据量后再批量写入parquet. 在读取column table时也会自动合并本地缓冲数据和parquet两部分数据, 使得查询到的数据延迟更低.

DuckDB AsOf Join 核心解析 https://mp.weixin.qq.com/s/uIP9RSEvrAdP0mDVPF2dWQ
- > 原文: https://duckdb.org/2025/02/19/asof-plans.html
- > DuckDB的AsOf Join是一种针对时间序列数据的特殊连接操作，主要用于处理时间戳不完全匹配的场景。
- > **一、`AsOf Join`的核心功能**
  * > **1.模糊时态匹配**
    + > ***当两个表的时间戳无法精确对齐时，AsOf Join会基于时间顺序，将左表的每条记录与右表中时间戳最接近且不超过左表时间的记录关联***。例如，计算某持仓时间点的最新价格（）。
  * > **2.典型应用场景**
    + > 金融领域：计算持仓在特定时点的价值（左表为持仓时间，右表为价格变动时间序列）。
    + > 数据对齐：合并不同频率的时间序列数据（如分钟级交易数据与日级因子数据）。

我为什么要搞数据库内核课程 https://mp.weixin.qq.com/s/vJ-2OiTvwDht9UsJebqhbg

DBA转型干内核开发行不行？ https://mp.weixin.qq.com/s/WDsu1ABbvzi8QXOcDqnVeQ

这样玩转 PolarDB 开源社区 https://mp.weixin.qq.com/s/ot9hB_5c4gxADaguDJqrgA

开发者福音！github AI助手 https://mp.weixin.qq.com/s/QtHTTGQLdyPRpeMaMKJQeg

PolarDB数据库基础 5 特性解读与体验 https://mp.weixin.qq.com/s/dhiVqjf9obm7Afzviro2pA
```console
PolarDB数据库基础 5 特性解读与体验
1、预读 / 预扩展
2、Shared Server
3、闪回表和闪回日志
4、弹性跨机并行查询（ePQ）
5、TDE 透明数据加密
```

# 01

微调实践 - 让AI学完所有PolarDB文章 https://mp.weixin.qq.com/s/63Fb8ZIHXNJ9XmUgUde4EQ

猛料! 月饼(pgmooncake)进化了 https://mp.weixin.qq.com/s/FtrfNAHVVn-Av0DsvHWHZQ
- > https://www.mooncake.dev/blog/how-we-built-pgmooncake
- > https://github.com/Mooncake-Labs/pg_mooncake/releases/tag/v0.1.0
- > 快看v0.1.0增加了什么? `pg_duckdb` 都还不能 JOIN with regular Postgres heap tables. 月饼已支持!

遇到炫技的面试官，千万别这样答！ https://mp.weixin.qq.com/s/WD3agUUkr-KOp1JRa8vqRw
- > `情况1`, PostgreSQL数据库正在执行long query时, 如果客户端(主动/被动)断开与PostgreSQL的socket连接, 或者中间网络设备断开了这条连接, 请问PG数据库有什么反应?
  ```console
  1、继续执行long query
  2、直到执行完long query, 然后send data, 发现socket连接不正常
  3、断开连接
  ```
  * > 有没有什么方法让PG更快的发现客户端连接已经断了? 立即终止执行long query呢?有, 例如配置
    + > `tcp_keepalives_idle = 10s` # 如果这个socket连接10s都没有数据, 操作系统内核将发起心跳包
    + > `tcp_keepalives_interval = 5s` # 如果心跳包没有收到客户端回包, 间隔5s后再次发送
    + > `tcp_keepalives_count = 3` # 重试3次还没有收到回包, 操作系统内核将这个socket置为close状态. 当前配置也就是10+5+5+5=25s后发现问题并close socket.
    + > `client_connection_check_interval = 10s` # `PG 14`引入的参数. 数据库每10s检查socket状态, 如果发现close, 则停止正在执行的query, 释放数据库服务端的socket.
  * > 如果没有配置 `client_connection_check_interval` 的话, 要等数据库进入等待客户端消息或向客户端发送消息时, 才能发现socket问题, 也就是long query执行完.
- > `情况2`, PostgreSQL数据库正在执行long query时, 如果客户端(主动并发起SIG cancel 信号, 不管它怎么发的, 例如通过Libpq协议)断开与PostgreSQL的socket连接, 请问PG数据库有什么反应?
  * > 这里提到了cancel 信号, 那就要分2种情况
    + > 1、如果PostgreSQL 处于不接收中断信号的执行过程, 则暂不响应中断信号, query会继续执行完.
    + > 2、如果PostgreSQL 处于可接收中断信号的执行过程, 则会立即cancel query.
