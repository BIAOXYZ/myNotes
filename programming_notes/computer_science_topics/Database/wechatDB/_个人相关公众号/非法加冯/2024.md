
# 11

你为什么不用连接池？ https://mp.weixin.qq.com/s/3uD9sxCg-lI1MlOg3NacvQ
- > 昨天遇到一个客户的案例。使用客户端直连 PostgreSQL，单个主库上有小几千条数据库连接。应用侧扩容之后连接数又大了很多，***4000 多条连接，1500 条活跃状态的连接，直接撞上了软件瓶颈，写性能退化严重。后来换成连接池访问之后问题解决了***。今天就来简单聊一下这个问题，连接池。
- > **高并发连接数**
  * > 在这个案例中，应用使用了 1500 条活跃的客户端连接访问单个主库。因为 PostgreSQL 使用多进程架构，这意味着对应着 1500 个后端进程，大部分的客户端请求只是单纯的向某张巨无霸表中插入单条数据，TPS 两万左右。然后就出现性能劣化的场景了，一条 INSERT 可能要上百 ms 才能返回，***而不是常规的上百 µs***。
  * > INSERT TPS 2万，不算很大的量。但怎么就卡死了呢？关键就在这个高并发连接数上。在这个系统中，硬件没有瓶颈，磁盘是 NVMe 的，CPU 使用率百分之十几。但是一千五百条连接争相抢着写入 WAL ，在这个系统中有大概 1000+ 的 LWLock 存在，大家都把时间花在毫无意义的内耗上了！
  * > 怎么解决，直接上 `pgBouncer`   ，上了 pgBouncer 之后，***最后活跃的数据库服务端连接数从 `1500` 变成了 `2`*** 。是的，***其实这两万 TPS，两条连接就可以解决问题了***。并不需要上千条连接。使用连接池之后，所有的 INSERT 请求都排队使用这两条连接，系统中的 LWLock 等待全都消失了，一切恢复平静。
  * > 其实这跟我们之前使用 pgbouncer 的经验相符，***之前我们有一套主库上挂着大概 3～4 万的 TPS，对应着 pgBouncer 中，只使用 3 ～ 4 条活跃连接就解决问题了***，两万条客户端连接有序排队，其实只要 4 条连接就能解决问题。[Cloudlfare 的一篇博客，也讲过这个问题](https://mp.weixin.qq.com/s/iH34payWSE_GROsq-9MN8g)。

面向未来数据库的现代硬件 https://mp.weixin.qq.com/s/0Y17J-opjq1fceRi8777Xg

这么吹国产数据库，听的尴尬癌都要犯了 https://mp.weixin.qq.com/s/MrRsK5lqZsCZwCUnnO1VMQ || https://web.archive.org/web/20241120120748/https://mp.weixin.qq.com/s/MrRsK5lqZsCZwCUnnO1VMQ  【已经有人先 web archive 存了。。。看来觉得这篇会被和谐的不在少数- -】
- > 最近有个国产数据库开了个发布会，看到圈子里几位数据库博主在推。老实说，看得人尴尬癌都犯了。
- > 这个数据库名字一看就是打爱国牌的玩家。还找了个院士背书。当然，你懂的。
- > 总之，专业人士是懒得看这些营销胡话的，我想看看有什么实质的东西。官网上，说自己有个什么 “有界计算” 核心科技，非常牛逼之类的。
- > 翻了半天， 总算搜到了这篇深圳计算院 “有界计算” 的论文。论起制造学术XX，俺还是颇有心得，一看这满屏的代数 —— 呵，熟悉的味道。
- > 简单看了一下关键部分，用 PostgreSQL 做实验，用 TPC-H 和其他俩分析场景做案例。TPC-H 仓数也很小，16GB，太迷你了 —— 有请 GPT 帮我确认下内容：
- > 核心科技 “有界计算” ：给 PG 加个条件索引。
- > 数据库加索引，所以会快。
- 回复：
  * > 这篇发的`International Journal of Automation and Computing`，反正ccf推荐的会议和期刊目录里是没有，到底什么档次深不可测；相关的另一篇`“Data Driven Approximation with Bounded Resources“`发在`vldb17`上，这个倒是ccf a类会议，或许看着更有价值点。另外，崖山之战是打输了也宁死不降的气节风骨，现在搞个新产品就叫崖山，难不成意思是虽然技术输的一塌糊涂，但是有自研的风骨？
    >> 看过了，类似，创建联合索引加速查询。
  * > 遥遥领先，遥遥领先。增智慧，增智慧。
  * > 和华为手机越来越像了，怀疑尬吹的人收了稿费
    >> 其实就是HW高斯当年的自研备胎，PG改路线上位，被抛弃后另寻宿主搞的。
    >>> 其实菊厂手机 和 现在db都有个通病：“用一些可有可无的微创新掩盖自己在发明国外已经发明过的东西这一个尴尬的事实”。信创的本质就是把西方已经做了的很成熟的东西自己再做一遍，这个事儿最大的阻力在别人会说已经有了xx我为什么用你的xxx？于是你做了半天可能根本没用户…
    >>>> 国人更擅长的是“微创新”，把别人走过的路再走一遍，中间搞些似有若无的发明，看起来确实好了一些，但是让他们去探索无人区，ROI太低。也许等到抄无可抄了，确实会出现一些牛逼的创新企业，但是不是现在。
    >>>>> 同意。而且我有点更悲观的看法，就目前国内情况看抄无可抄了可能都不去创新，大概率就是一部分想创新的人离开了，留下的躺平….
  * > 期待着写入控标项。。。
  * > 爱国生意兴隆
  * > 没办法啊，现在都在吹
  * > 不是很理解，为什么他们喜欢拿PG下手，不对SQLite动刀呢？
    >> PG扩展性强，可以做插件甚至可替换内核，sqlite是针对特定场景的，别看小但代码质量很高，对国产厂家来说改起来太难
  * > 国产数据库甚至没能实现自兼容，耶不要觉得国产就便宜，售价与维护费远超oracle，用起来嘛见仁见智
    >> 哪有上线不成功的, 不成功的都下课了,或进去了.
  * > 你这个人，好不晓事！还能做朋友不？还能一起嗨不？还想不想登台领奖吹牛逼了？嫩模会所不想去了？温哥华新加坡不想走了？回去反思反思！
  * > 冯总，这么年轻就要患上癌症了？？
  * > 拳打 Oracle ，脚踢 MySQL ，肘击 PG ，就问你：我们信创 db 牛逼不牛逼？
    >> 牛逼～～～～破音）
  * > 这些db掮客站台的时候不觉得尴尬嘛！
    >> 挣钱嘛不寒碜
  * > 数据库这种被玩烂多年的东西，竟然还能有创新，它们玩的挺花呐
  * > 这文章一放出来，深圳，要发文骂你了
  * > 人家用三年时间迭代了23个版本，YashanDB V23.3版本， 吊打Oracle，中国版Oracle！！！
  * > 图片保存本地了，准备发个朋友圈。哈哈哈

号外：发布当日叫停，PG也躲不过翻车 https://mp.weixin.qq.com/s/l1BgfLaRKNNEqHyfx33E6A
- > 老话说的好，不要在星期五发布代码。前天刚发布的 PostgreSQL 例行小版本虽然特意避开了星期五发布，但却给社区加了一周的活 —— PostgreSQL 社区将于下周四发布一个非常规紧急小版本 PostgreSQL 17.2，16.6， 15.10，14.15，13.20，甚至是刚刚已经 EOL 的 PG 12 也会有 12.22…… ，并将先前的小版本废弃回滚掉。
- > 在过去十年里这是第一次出现这样的情况：在 PostgreSQL 发布日的当天，新版本就因为社区发现的问题而叫停。紧急发布的原因有两个，第一是修复 CVE-2024-10978 安全漏洞，这个不是大问题，真正的原因是：***PostgreSQL 新的小版本修改了 ABI，导致依赖 ABI 的扩展崩溃***。
- > 目前发现受影响的插件包括 `TimescaleDB` 与 `AGE`。前者是 PG 生态的一个核心重磅扩展插件，提供时序数据库、流式聚集等能力，后者在 PostgreSQL 提供图数据库的能力与 OpenCypher 图查询语言。
- > 关于 PostgreSQL 小版本 ABI 兼容性的问题，在今年六月 PGConf 2024 上，Yuri 在扩展峰会上和《Pushing boundaries with extensions, for extension》的演讲中其实已经抛出过这个问题，但并没有得到过多的关注。结果这次结结实实的爆炸了，我猜 Yuri 看到这个新闻肯定会耸耸肩说：Told you so。

:u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272:

# 08

谁整合好DuckDB，谁赢得OLAP数据库世界 https://mp.weixin.qq.com/s/TJk9TUW7xsEglhEK_qYi-w
- > **DuckDB的短板与其中的机遇**
  * > 可以预期的是，市面上一定会很快出现一系列的 DuckDB 套壳产品来解决这里的摩擦与GAP。正好比当年 Facebook 开源了 KV 数据库 `RocksDB` ，无数 “新的数据库” 给 RocksDB 套了一层 SQL 解析器，就号称自己是新一代数据库去圈钱了 —— Yet another SQL Sidecar for RocksDB。向量检索库 `hnswlib` 开源后，无数 “专用向量数据库” 给它套了薄薄一层皮，就去市场上圈钱了。然后搜索引擎 `Lucene` 和下一代替代 `Tantivy` 开源之后，又有无数“全文检索数据库”来给他们套壳卖。
  * > 实际上，这样的事情已经在 PostgreSQL 生态中发生了。在其他数据库产品和公司还没来得及反应之前，PG 生态已经有五个玩家下场赛马了，包括 `ParadeDB` 的 `pg_lakehouse`，国内个人开发者李红艳编写的 `duckdb_fdw`，`CrunchyData` 的 `crunchy_bridge`， `Hydra` 出品的 `pg_quack`；以及目前 `MotherDuck` 原厂也跑过来做 PG 扩展了 —— `pg_duckdb`。
- > **第二届PG扩展竞速比赛**
  * > 这不禁让我想起了过去一年中，PG生态里向量数据库扩展的例子。AI爆火之后，PG 生态里就涌现出了至少六款向量数据库扩展（ `pgvector`，`pgvector.rs`，`pg_embedding`，`latern`，`pase`，`pgvectorscale`），并在你追我赶的赛马中卷出了新高度。最后 `pgvector` 在以 AWS 为代表的厂商大力投入加持之下，在其他数据库比如 Oracle / MySQL / MariaDB 姗姗来迟的糊弄版本出来之前，就已经把整个专用向量数据库细分领域给摧毁荡平了。
  * > 原本 Fork `Citus` 列存扩展的 `Hydra` （YC W22），在尝试构建 `pg_quack` 感受到 DuckDB 震撼后，立刻抛弃原有的引擎和 MotherDuck 合作，搞出来了 pg_duckdb。融合了 PG 生态经验的 Hydra 与 DuckDB 原厂弄的扩展，可以直接在数据库内丝滑地读取 PG 数据表，并使用 DuckDB 引擎进行计算，***并且可以直接从`文件系统/S3` 上读取 `Parquet / IceBerg` 格式的文件，实现湖仓的效果***。
  * > 同样是 YC 投的初创数据库公司 ParadeDB （YC S23），在尝试了自己用 Rust 构建类似的分析产品 pg_analytics 并取得了不俗的成绩之后，也选择改换了路线，基于 DuckDB 打造 pg_lakehouse 扩展。当然，创始人 Phillipe 在 pg_duckdb 刚刚官宣之后也立刻宣布投降，准备在 pg_duckdb 的基础上进行进一步的开发而不是当竞品。
  * > 国内个人开发者李红艳开发的 DuckDB FDW 是另一条另辟蹊径的道路。***不是直接利用 PG的存储引擎接口，而是直接用外部数据源包装器（FDW）的基础设施，将 PG 和 DuckDB 对接到了一起。这引发了官方亲自下场吐槽，将其作为反例批判***，也许是 MotherDuck 亲自下场的一个动机：“我还在构思伟大蓝图，如何融合PG与Duck的力量，你小子动作也太快了，得给你一点官方震撼看看”。
  * > 至于 CrunchyData 搞的 cunchy_bridge ，或者其他数据库公司搞的闭源套壳扩展，我个人感觉是很难有出息的。

# 01

令人惊叹的PostgreSQL可伸缩性 https://mp.weixin.qq.com/s/iH34payWSE_GROsq-9MN8g
- > Cloudflare是如何用15个PG集群支持55M QPS的 https://newsletter.systemdesign.one/p/postgresql-scalability
- > 现在他们承载着 `20%` 的互联网流量，每秒 `5500 万`个 HTTP 请求。而他们仅仅使用 `15` 个 PostgreSQL 集群就做到了这一点。
- > Cloudflare 使用 PostgreSQL 来存储服务元数据，并处理 OLTP 工作负载。然而在同一个集群支持有着多种不同负载类型的租户是一个难题。一个集群（Cluster）是一组数据库服务器，一个租户（tenant）是特定用户或用户组专用的隔离数据空间。

:u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272:
