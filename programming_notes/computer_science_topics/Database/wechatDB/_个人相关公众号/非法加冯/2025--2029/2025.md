
# 11

原地报废：不要在生产环境用Docker跑PostgreSQL！ https://mp.weixin.qq.com/s/9q68rfefIVdU9cjwDfUxGg
- > 为什么排序规则很重要
  * > 那么，为什么会出现这个问题呢？老冯在[`《PG中的本地化排序规则[2]》`]()就深入聊过这个问题。 简单的结论就是你应该始终使用 C.UTF-8 作为全局排序规则，同时在 PostgreSQL 17 之后的版本则应该强制使用 PG 内置的 locale provider，而不是使用操作系统 glibc 的排序规则。 真的要用到特定 Locale 规则的时候（什么汉语拼音排序之类的），直接在 DDL / SQL 里面显式声明就可以，不影响使用的 —— 用 ICU 排序规则，不要使用操作系统的！

PG扩展云，免翻免费解锁PG完全体 https://mp.weixin.qq.com/s/oHHzhbbt5suSxnJhyxTwQQ
- > 无可比拟的数量
  * > 官方仓库不收录这些扩展有许许多多的原因 —— ***比如 YUM 仓库的维护者 Devrim 就表示，绝对不会让 Rust 写的 PG 扩展进入仓库中***。 而像 plv8，pg_duckdb 这样一编译一个小时的扩展巨无霸，毫无疑问也会显著拉高仓库维护的成本，所以老冯也完全能理解。
- > 如何分发扩展
  * > 在我之前的文章 从PG“断供”看软件供应链中的信任问题 和 卡脖子：PostgreSQL切断镜像站同步通道 中， 我曾提到：PostgreSQL 官方 PGDG 仓库自今年5月起停止了 ftp/rsync 同步通道，这导致全球范围内的大部分镜像站从那时起就不再更新了。 
  * > 对于海外用户来说影响尚不明显，但对于中国大陆用户而言，这意味着如果不翻墙就无法获取 PG 的最新软件包。 大家常用的阿里云、清华 TUNA 镜像源目前都停留在 2025-03-31 的版本，仓库连今年 9 月发布的 PG 18 都影子无踪。
- > PG扩展维基百科
  * > PGEXT.CLOUD 的扩展目录（即通过  https://pgext.cloud [1] 访问的网页），汇集了前述 431 个扩展的详细信息。 我们为每个扩展整理了元数据、在各操作系统和 PG 版本上的可用性矩阵，以及完整的安装、配置与加载使用说明。
- > 简单易用命令行
  * > 当然，更令人兴奋的是，我们还提供了简单易用的命令行工具 pig。这个用 Go 语言编写的小巧工具（仅 4 MB），将 PostgreSQL 的安装和扩展交付过程简化到了极致。
  * > 例如，只需下面三行命令，就可以分别完成下载 pig、配置仓库以及安装 PG 内核和扩展插件：
    ```sh
    curl -fsSL 
                https://repo.pigsty.io/pig
              | bash
    pig repo set
    pig install -y -v 18 pgsql postgis pg_duckdb 
    ```
  * > 无论您使用的是哪种 Linux 发行版，配置了什么软件源，所处地域网络如何，使用 dnf/yum 还是 apt，这个工具都能替您处理好所有细节。
  * > 值得一提的是，pig 并非另起炉灶造轮子，而是对现有 Linux 包管理器的“一层薄皮封装”（PiggyBack）。 换言之，您依然可以使用经典的 apt/yum 来直接访问 PGEXT.CLOUD 的软件仓库 —— pig 只是让这一切变得更简单，但并不是不可替代的强制依赖，更不会引入任何供应商锁定。
- 回复：
  * > pig build 命令能不能构建其他开源软件rpm/deb包（非pg扩展）
    >> 只要自己写 SPEC / Control 文件就能…照猫画虎在 pgsty/rpm pgsty/deb 里加上类似 scws / libfq 这种非扩展依赖的定义就好。

# 10

GPT5/Claude：国产数据库行业研究对比 https://mp.weixin.qq.com/s/N_O5HS4o2bSXISQLzAVq7g  【`10.14`】

# 06

AI时代的数据库与DBA将何去何从 https://mp.weixin.qq.com/s/hXcbO5DVK3y84AgADQoUMQ  【`6.30`】
- > **一体化还是专业化，如何选型？**
  * > 前些日子，有个朋友问我一个向量 RAG 场景，应该用 PostgreSQL + pgvector 还是 Milvus，我问你有多少数据量 —— 两千万条。我回复说这个数量级您就别折腾了，`一百多GB`的数据放 PG 洒洒水，`十几TB` 的PG向量表我都见过照样跑的好好的。你要是数据量再翻个几百倍，[有淘宝图搜图百亿千亿量级的场景，用一个专用向量数据库很合理](https://mp.weixin.qq.com/s/0eBZ4zyX6XjBQO0GqlANnw)，而你现在已经用着PG，这么点规模就开始折腾，那不是给自己找事吗？
  * > 同理，我也见过好几次有业务号称自己有超高增长，一上来就要申请一套水平分片库，最后只有 几十GB数据的滑稽故事。如果你的数据连几十TB都没有，那根本用不上什么分布式 NewSQL 数据库 —— [OpenAI 可以用一套一主四十从PG支持五亿月活](https://mp.weixin.qq.com/s/ykrasJ2UeKZAMtHCmtG93Q)，那 99.99% 的业务也可以靠一个 PostgreSQL 解决所有问题。[分布式数据库是伪需求](https://mp.weixin.qq.com/s/FNhTCZk-SBVQkYhQ3zi_-g)，[甚至也开始对 OLAP 分析/大数据成立了](https://mp.weixin.qq.com/s/rfv_oSRD4LS-W9xFd_WB9g)。

# 05

阿里云：从上到下烂到根了【去除原文版】 https://mp.weixin.qq.com/s/0pT7wb0Y6ohgvEltED93hA

~~阿里云：从上到下烂到根了 https://mp.weixin.qq.com/s/C184Www3Zh6mmHX9wqe1cA~~

小数据的失落十年：分布式分析的错付 https://mp.weixin.qq.com/s/rfv_oSRD4LS-W9xFd_WB9g  【`5.23`】
- > 作者： Hannes Mühleisen，发布于 2025 年 5 月 19 日
- > 包括我们自己在内，很多人都反复提到过这一点：数据其实没那么大[2] 。而且硬件进步的速度已经超越了有用数据集规模的增长速度。我们甚至预测预测过 在不久的将来会出现“数据奇点”[3] ——届时 99% 的有用数据集都能在单节点上轻松查询。最近的研究数据显示[4] ，`Amazon Redshift` 和 `Snowflake` 上的查询中位扫描数据量仅约 `100 MB`，而 99.9 百分位点也不到 `300 GB`。由此看来，“奇点”也许比我们想象的更近。
- > **复现**
  * > 所有二进制文件、脚本、查询和结果都已发布在 GitHub[15] 上供大家查阅。我们还提供了 TPC-H SF1000 数据库文件[16] 下载，这样你就不用自己生成。不过请注意，文件非常大。
- > **老冯评论**
  * > 例如国产数据库标杆 TiDB 主打 HTAP 概念，并提供了 TiFlash 用于分析加速。然而其官网公布的 TPC-H 评测结果，用 92C 478G 处理 50 仓的数据，耗时几乎和一台 10C64GB 笔记本处理 300 仓的接近，***在相同的时间里用十倍的资源却只处理了 1/6 的数据***。这不禁让人怀疑，在分析这趴用分布式到底有多大意义？

OpenAI：将PostgreSQL伸缩至新阶段 https://mp.weixin.qq.com/s/ykrasJ2UeKZAMtHCmtG93Q  【`5.19`】

# 04

分布式数据库是伪需求 https://mp.weixin.qq.com/s/FNhTCZk-SBVQkYhQ3zi_-g  【`4.22`】

OrioleDB 奥利奥数据库来了！ https://mp.weixin.qq.com/s/QG7_UyT08fNFiBj6qujSEA  【`4.6`】
- > 极致吞吐性能
  * > OrioleDB 旨在解决这个问题，根据它们官网首页的宣称，他们的读 / 写吞吐可以达到 PostgreSQL 的四倍，老实说这是一个相当惊人的数字 —— 40% 的性能提升不足以成为使用一个新存储引擎的理由，但 400% 确实可以成为一个不错的理由了。
  * > 首先 OrioleDB 的杀手特性是性能，针对垂直伸缩高度优化，吞吐性能更强大。号称在当代硬件上吞吐可以达到标准 PG 的四倍。
  * > 当然这里有一些相对于 PG 堆表的关键优化，比如去掉了 FS Cache，内存页面直接链接到存储页面，内存页面可以无锁访问，另外使用 UNDO 日志/回滚段来实现 MVCC 而不是 PG 的 REDO，还有易于并行化的行级WAL。
- > 简化运维
  * > ***PostgreSQL 中最 “臭名昭著” 的问题莫过于 `XID Wraparound`，另一个让人 “心烦” 的问题则是`表膨胀`***，而这两个问题都源于 PostgreSQL 的 MVCC 设计。
  * > OrioleDB 旨在通过一款新的存储引擎解决这个问题 —— 可以粗略理解为，它使用类似 Oracle / MySQL 的存储引擎方案，同时继承了 O/M 的优缺点。比如，因为使用了新的 MVCC 实践，OrioleDB 存储引擎的表不会再有膨胀与 XID 回卷的概念了。
  * > 当然，有得必有失，这样设计当然也会继承这样设计的缺点，比如大事务问题，回滚慢问题，分析性能问题。但它的好处是可以把海量 OLTP CRUD 这个单一场景的性能做到极致。
- > 还有其他内核花活
  * > 当然，这里支持的 PG 分支内核可不止 OrioleDB 一个，你还可以使用兼容微软 SQL Server 的 `Babelfish` （由 AWS 出品），兼容 Oracle 的 `IvorySQL` （由瀚高出品），兼容 MySQL 的 `openHalo` （由易景科技出品），Aurora RAC 风味的 `PolarDB` 内核（由阿里云出品），以及正儿八经带有国产信创资质，Oracle 兼容的 `PolarDB O 2.0` 内核。

# 03

Dify被重复骑脸羞辱：我太难了！ https://mp.weixin.qq.com/s/7BuuCAQbJ5jwSP28XSmdHQ
- > 今天 Dify 的 GitHub 仓库上演了一出魔幻现实大戏，Dify 开源社区好好地维护着自己的仓库，没想到忽然收到了一个（不止一个，还连着两个！）疑从`丽珠医药`发来的 PR，手起刀落就把 Dify 的 Logo 给换了。
- 回复：
  * > 03-28 更新：丽珠医药集团相关人士表示：集团邮箱被盗，已经报警。
    >> 临时工是吧

PGFS：将数据库作为文件系统 https://mp.weixin.qq.com/s/Oa3VRbcac8WSSc7YY3hVvA
- > 前几天，我收到了一条来自 Odoo 社区的需求，对方苦恼于：“数据库能做PITR（Point-in-Time Recovery），那文件系统有没有办法一起回滚呢？”
- > **初识JuiceFS：让数据库“化身”文件系统**
  * > JuiceFS 安装与使用非常轻量，就是一个 Go 二进制程序，只需一行命令即可完成格式化、挂载、读写。比如以下命令，就能把 SQLite 作为JuiceFS的元数据存储，并把本地路径当作对象存储来测试：
    ```sh
    juicefs format sqlite3:///tmp/jfs.db myjfs     
    juicefs mount sqlite3:///tmp/jfs.db ~/jfs -d
    ```
- > **性能表现如何？**
- 回复：
  * > 数据放 minio，开启回收站，可以在回收站时间内实现任意会滚，就没有容量和性能限制了
    >> 这是正规玩法，不过MinIO那个回滚要自己写脚本过滤，有点麻烦，跟PG同步PITR就更麻烦了 —— 最主要的是，享受不到拎着一个PG就走的快乐了

HTAP数据库，一场无人鼓掌的演出 https://mp.weixin.qq.com/s/wxOSAjObi0oiiRPRahWjJQ
- 回复：
  * > 很多公司，要的htap，也只是想要个列存加速来补一补索引外的速度。
  * > 可能您接触的都是大公司，但其实但大部分公司的数据源并没有那么复杂。
    >> 大部分公司, 搞个主从,用上`pciessd+大内存`, 订单/分析 都够用了. 更大的公司,自己定制,岂不美哉? 哈哈哈哈
  * > 类似 tidb 这种底层处理方式，挺滑稽的，表面上融合了 olap 和 oltp 实现上还是都是分开的，何必强行捆绑在一起

# 02

什么？PG小版本发布又翻车了？ https://mp.weixin.qq.com/s/5HqebxJvBkNu4JybKvTCwQ

# 01

花钱买罪受的大冤种：逃离云计算妙瓦底 https://mp.weixin.qq.com/s/zwJ2T2Vh_R7xD8IKPso31Q

PII数据安全合规与PG Anonymizer最佳实践 https://mp.weixin.qq.com/s/U3go6FneJhp2IPZ6wtiWAA
