
# 05

MonetDB/X100: Hyper-Pipelining Query Execution - 梁辰的文章 - 知乎 https://zhuanlan.zhihu.com/p/376227899
- > 这是关于`MonetDB`执行引擎的一篇paper，总体分为了2个部分，第一部分主要讲了下modern cpu的工作原理并给出了一些例子，从这部分中我们便可以清晰的看到为什么向量化的执行方式如此有意义。第二部分则主要介绍了`MonetDB X/100`这个新的向量化执行引擎。
- > **介绍**
  * > 因此`MonetDB/X100`这种向量化模型实际是`tuple-at-a-time`的`volcano`和`column-at-a-time`的`全物化`之间的折中方案，很好的提升了CPU执行效率。
- > **现代CPU**
  * > 从上图可以看到，1条指令的执行划分为了5个stage，就像流水线上的工人一样，每个stage的工人处理完一条instruction后立即开始对下一条instruction的同一个stage进行处理，这样就让CPU的各个组件随时都在工作，提升了CPU的时钟频率。
  * > 当然，大多数编程语言（包括C/C++)都不需要编程人员去指定指令之间的独立性，这需要由compiler来完成，因此compiler的优化能力对于cpu的充分利用就变得很重要，其中一个很重要的优化就是`loop pipelining`（**这也是vectorize所追求的**)：
  * > 可以看到，手工重写后的版本将不带有分支的if语句，因此其执行效率更高，且和选择率无关。(Itanium2自带编译优化，***可以将branch version -> predicated version***)
- > **Micro benchmark**
  * > 本节针对`TPC-H(1S) Q1`的执行进行了分析，选择Q1是因为只想关注最基本的表达式计算，不考虑像join这样更复杂的关系运算，也不受太多查询优化的影响。
  * > 上图是MySQL4.1中对于Query 1的执行分析，***`cum`是该操作累计执行时间，`excl`是该函数自身执行部分所在比重（排除它调用的其他函数），`calls`是调用次数，后两列是每次call执行的`平均指令数`和`IPC`***。
  * > 可以观察到，上图中5个加重的函数是实际执行运算的部分，它只占总体执行时间的10%，还有28%用在了hash table lookup中，另外62%则被`rec_get_nth_field`这类的辅助解析函数等占用。
  * > 在MIPS R12000 CPU下，仔细查看`Item_func_plus::val`这样的实际计算函数，每次加法使用了38个instructions，而这种CPU每个cycle可以执行3个普通的整型/浮点型addition指令和一个`load/store`指令，每个操作的延迟大概在5cycle。一个简单的加法运算在RISC指令集上：
    ```risc
    +(double src1, double src2) : double
    =>
    LOAD src1,reg1
    LOAD src2,reg2
    ADD reg1,reg2,reg3
    STOR dst,reg3
    ```
  * > 这套操作中比较重的是`LOAD/STORE`指令，因此一个加法运算大概是`3个周期`（`3个LOAD/STORE`），而在MySQL中得到的，则是 `#ins/IPC = 38/0.8 = 49`，要这么多个cycle才能完成一个加法运算！
  * > 其中一个原因就是MySQL的这种tuple-at-a-time的方式无法实现`loop pipelining`的优化，每个指令都要等待其完成(`5 cycle`)才能执行下一个，这样光是这4个指令就要`4*5 = 20`个cycle了。剩下的`29`个cycle则来源于函数的调用，stack的建立，入栈出栈这些。
  * > paper中同样测试了一款流行的商业数据库，得到了类似的结果（高度怀疑是Oracle）。
  * > `MonetDB`的数据存储方式是BAT(Binary Association Table)，每列数据都以二元组[oid,value]来表示，oid表示tuple的唯一标识。
  * > 对MonetDB/MIL执行query 1，可以看到一共20个MIL的操作占用了99%的执行时间（MySQL只有10%)。仔细观察下第2列和第4列，会发现当数据量较大时(SF = 1)，执行受到了memory bandwidth的限制，最大只能到500M/s，而如果数据量小(SF = 0.001)，所有数据到保存在cache中，cpu <-> cache间的吞吐可以达到1500M/s。对于一列计算，输入+输出一共占用16 + 8 = 24个字节，因此500MB的带宽意味着每秒20M的操作次数，如果是1533MHz CPU，则等于每个操作占用75 cycles，还不如MySQL的49 cycles！
  * > 因此这种column-at-a-time的执行方式产生了正反两面的影响：
    + > 正面上，不再有tuple-at-a-time的解析成本，由于操作的是整个column vector，可以充分利用loop pipelining
    + > 负面上，由于运算结果的全量物化，导致在计算中会经常需要大量的memory IO操作。
  * > 为了得到在现代CPU上最为理想的执行性能作为baseline，paper中实现了一个c代码的UDF：
    ```c
    static void tpch_query1(int n, int hi_date,
                            unsigned char*__restrict__ p_returnflag,
                            unsigned char*__restrict__ p_linestatus,
                            double*__restrict__ p_quantity,
                            double*__restrict__ p_extendedprice,
                            double*__restrict__ p_discount,
                            double*__restrict__ p_tax,
                            int*__restrict__ p_shipdate,
                            aggr_t1*__restrict__ hashtab)
    {
      for(int i=0; i<n; i++) {
        if (p_shipdate[i] <= hi_date) {
          aggr_t1 *entry = hashtab + (p_returnflag[i]<<8) + p_linestatus[i];
          double discount = p_discount[i];
          double extprice = p_extendedprice[i];
          entry->count++;
          entry->sum_qty += p_quantity[i];
          entry->sum_disc += discount;
          entry->sum_base_price += extprice;
          entry->sum_disc_price += (extprice *= (1-discount));
          entry->sum_charge += extprice*(1-p_tax[i]);
        }
      }
    }
    ```
  * > 在MIL中，目标列以`BAT[void,T]`的形式存储，其中void(virtual-oid)是不实际存储的，因此输入的就是普通array。通过 `__restrict__` 描述数组间不重叠，这样就可以应用loop pipelining，***从本节第一张图可以看到，手写的执行时间只有`0.22秒`，远优于`MySQL`和`MonetDB/MIL`***。
- > **X100 : A Vectorized Query Processor**
  * > X100是一种全新的执行引擎，其思路是结合Volcano这种`tuple-at-a-time`的流水线和MIL的`column-at-a-time`的无流水线全量物化，做一个折中，每次处理一个批次的列数据。
- > **总结**
  * > `MonetDB`应该算是向量化执行引擎的始祖？这篇paper用非常严谨的分析说明了传统的volcano那种`tuple-at-a-time`的执行方式在分析型场景下是如何的低效，或者纯粹的按列物化的方案所存在的memory bound问题，因此采用了折中方案：
    + > 流水线的执行算子
    + > 小的，连续内存的，常驻cache的，固定类型数组作为计算单元(vector)
  * > 各取所长，便是vectorized执行引擎了，具体的实现要依赖大量vectorized primitives，在其中也可以利用SIMD做进一步优化。
- 回复：
  * > 请问一下， selection-vector 和 bitmap. 有什么区别么？还是用 bitmap 就可以实现 selection-vector
    >> 这里没什么区别，bitmap也可以
  * > 是说每次数据都会拷贝而不是原地更新吗...
    >> 不是，就是同一块内存数据，比如进行了过滤，他不会改变原来的数据，而且用一个vector描述其中哪些数据被过滤掉了，这样可以避免对原数组的改动，保持cache效率
    >>> 但是这样也不可避免的会造成内存的消耗吧？另外一个问题是，经过过滤以后，上层算子的处理的数据量就会少于1000行？如果要攒够1000行，那么极端情况，下层算子就要保存非常多的vector。是不是这样？
    >>>> 我理解是这样的，但vector可以做的很紧凑比如按bit做标识，这样内存压力会小很多，另外x100是批量流水线，后续数据被消费后，对应的vector也就释放了
