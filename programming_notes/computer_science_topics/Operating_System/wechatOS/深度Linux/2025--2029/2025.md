
# 12

Linux性能瓶颈突破：基于BPF的内核级透视 https://mp.weixin.qq.com/s/AEI1TzKhNJ_6ojEBl6c78w  【`12.17`】
- > 一、什么是BPF？
  * > 1.1 BPF的概述
    + > `BPF`，即`伯克利数据包过滤器`（`Berkeley Packet Filter`），最初诞生于 `1992 年` ，由 Steven McCanne 和 Van Jacobson 开发，旨在解决网络数据包过滤的效率问题。在当时，网络数据处理面临着诸多挑战，传统的包过滤技术效率低下，无法满足日益增长的网络流量需求。BPF 的出现，犹如一场及时雨，它允许用户在内核空间运行过滤代码，极大地提高了网络数据包处理的效率，相比当时的其他技术快了 20 倍之多。`tcpdump` 这个广为人知的网络抓包工具，就是基于 BPF 技术实现的。它让网络管理员能够轻松地捕获和分析网络数据包，就像拥有了一把精准的手术刀，可以对网络流量进行精细的剖析。
    + > 随着时间的推移，计算机系统变得越来越复杂，应用场景也日益多样化。传统的 BPF 逐渐显露出其局限性，它的功能较为单一，难以满足日益增长的内核编程需求，就如同一个只能在特定领域发挥作用的专家，无法适应更广泛的工作要求。于是，在 `2014 年`，`扩展伯克利数据包过滤器`（`eBPF`，`Extended Berkeley Packet Filter`）应运而生 。***eBPF 对传统的 BPF 进行了全面扩展，使其从单纯的网络过滤工具，华丽转身为一种通用的内核编程技术***，拥有了更强大的功能和更广泛的应用领域，成为了一个能够适应多种复杂工作的多面手。

# 11

从原理到实战：彻底搞懂Linux OverlayFS https://mp.weixin.qq.com/s/SoJhsEFWXdHpQ3miweAT6g  【`11.13`】

# 07

C++高并发三板斧：多进程、多线程、IO多路复用 https://mp.weixin.qq.com/s/1luDUh0_whjLjtkTqSO1iw  【`7.1`】

# 06

解锁C++异步编程：告别阻塞，拥抱高效 https://mp.weixin.qq.com/s/qB_5ux0VVTGpk8OOVAIXFQ  【`6.29`】

深入解剖io_uring：Linux异步IO的终极武器 https://mp.weixin.qq.com/s/7zVxYN3qwCgZL6QJ6AmKCw  【`6.26`】
- > **Part 3 `io_uring`原理剖析**
  * > **3.1 核心概念**
    + > (1) 环形缓冲区
      - > ***io_uring 的核心是两个`环形缓冲区`***：`提交队列（Submission Queue，SQ）`和`完成队列（Completion Queue，CQ）`。这两个队列在内核态和用户态之间共享，通过`内存映射（mmap）`的方式实现。
      - > 提交队列（SQ）用于存放用户程序提交的 I/O 请求。当用户程序需要进行 I/O 操作时，它会创建一个`提交队列条目（Submission Queue Entry，SQE）`，并将其放入 SQ 中。每个 SQE 包含了 I/O 操作的详细信息，如操作类型（读、写等）、文件描述符、缓冲区地址、数据长度等。
      - > 完成队列（CQ）用于存放内核完成 I/O 操作后的结果。当内核完成一个 I/O 操作后，会将对应的`完成队列条目（Completion Queue Entry，CQE）`放入 CQ 中。CQE 包含了 I/O 操作的返回值（如读取或写入的字节数、错误码等）以及用户在 SQE 中设置的用户数据。
      - > 环形缓冲区的工作方式基于生产者 - 消费者模型。***用户程序是 SQ 的生产者，内核是 SQ 的消费者；内核是 CQ 的生产者，用户程序是 CQ 的消费者***。通过这种方式，***io_uring 实现了用户态和内核态之间高效的通信，减少了系统调用的次数和数据拷贝的开销***。例如，***在传统的 I/O 模型中，每次 I/O 操作都需要进行系统调用，从用户态切换到内核态，而 io_uring 通过共享的环形缓冲区，用户程序可以直接将 I/O 请求放入 SQ，内核从 SQ 中获取请求并处理，处理完成后将结果放入 CQ，用户程序再从 CQ 中获取结果，避免了频繁的系统调用和上下文切换***。
    + > (2) 异步 I/O 操作
    + > (3) 批量操作与更多操作支持
  * > **3.2 工作原理**
    + > (1) 提交队列（SQ）工作流程
    + > (2) 完成队列（CQ）工作流程
    + > (3) 内核与用户态交互
  * > **3.3 系统调用详解**
  * > **3.4 工作流程深度剖析**
- > **Part 4 `io_uring`应用实例**
  * > **4.2 io_uring案例分析**
  * > **4.3 性能对比测试**
    + > ⑶测试结果分析
      - > 文件读写性能：在小文件（1MB）读写测试中，`阻塞 I/O` 由于线程阻塞等待 I/O 操作完成，导致其吞吐量最低，平均吞吐量约为 `50MB/s`。`非阻塞 I/O` 虽然避免了线程阻塞，但频繁的轮询使得 CPU 利用率较高，且由于 I/O 操作的碎片化，其吞吐量也不高，平均约为 `80MB/s`。`epoll` 在处理多个文件描述符的 I/O 事件时，通过高效的事件通知机制，提高了 I/O 操作的效率，平均吞吐量达到 `120MB/s`。
- > **Part 6 使用 `io_uring` 的注意事项与挑战**
  * > **6.1 内核版本要求**
    + > io_uring 是 Linux 内核提供的特性，对内核版本有一定的要求。要充分利用 io_uring 的全部功能，建议使用 Linux 5.10 及以上版本的内核 。在较低版本的内核中，可能不支持 io_uring，或者虽然支持但存在功能缺陷和性能问题。在 Linux 5.4 版本之前，io_uring 的某些功能可能不够稳定，在处理某些复杂的 I/O 操作时可能会出现错误。如果你的系统内核版本较低，在考虑使用 io_uring 之前，需要先升级内核。内核升级过程可能会涉及到系统兼容性、驱动程序等一系列问题，需要谨慎操作。在升级内核之前，最好备份重要的数据，并在测试环境中进行充分的测试，确保升级后的系统能够正常运行。
  * > **6.2 编程复杂度**
    + > 虽然 io_uring 提供了强大的功能，但直接使用 io_uring 的系统调用进行编程是比较复杂的。它涉及到对提交队列（SQ）和完成队列（CQ）的详细操作，以及对各种 I/O 请求参数的设置。开发者需要深入理解 io_uring 的工作原理和机制，才能正确地使用它。例如，在设置提交队列条目（SQE）时，需要准确地设置操作码、文件描述符、缓冲区地址、数据长度等参数，任何一个参数设置错误都可能导致 I/O 操作失败。在处理完成队列条目（CQE）时，也需要正确地解析操作结果和错误码，进行相应的处理。
    * > ***为了简化 io_uring 的使用，开发者可以借助 `liburing` 库***。liburing 库是对 io_uring 系统调用的封装，提供了更高级、更易用的 API。通过 liburing 库，开发者可以更方便地初始化 io_uring 实例、提交 I/O 请求、获取完成事件等。使用 liburing 库中的 `io_uring_queue_init` 函数可以方便地初始化 io_uring 实例，使用 `io_uring_get_sqe` 函数可以从提交队列中获取一个空闲的 SQE，使用 `io_uring_submit` 函数可以提交 I/O 请求等。借助 liburing 库，开发者可以降低编程的复杂度，提高开发效率，但同时也需要了解 liburing 库的使用方法和相关的函数接口。

# 04

深入探索bpftrace：Linux性能分析的新利器 https://mp.weixin.qq.com/s/XdFuAndAPh0IIVWtsUefjA  【`4.2`】

# 03

告别代码Bug，GDB调试工具详解 https://mp.weixin.qq.com/s/yzS44tOZDO6Yayh5jzCYUg  【`3.28`】

高效使用内存：掌握Linux中的堆管理技巧 https://mp.weixin.qq.com/s/0yDrHOwGRmJEUjYz0Yq6Ew  【`3.15`】

一文搞懂磁盘 I/O，基础扫盲来了！ https://mp.weixin.qq.com/s/irCeAkc0JPoukr3Y9KzXcQ  【`3.6`】

C++高频面试题：网络编程核心技术详解 https://mp.weixin.qq.com/s/NlfYJ5FHR3a48x6me2K3Fg  【`3.1`】

# 02

腾讯一面：malloc是如何分配内存的，free怎么知道该释放多少内存？ https://mp.weixin.qq.com/s/7Hb0EstO9CXzXz3L6rwtiw

深入探讨Ceph：分布式存储架构的未来 https://mp.weixin.qq.com/s/bt03PI4msFGjIV5_mhQJPQ  【`2.23`】

Linux C++编程死锁排查：借助Shell与GDB找到真相 https://mp.weixin.qq.com/s/aXvY2m5a1AIvzB5fC1FESw  【`2.22`】

当Linux程序“跑路”：利用Backtrace快速精准定位“案发现场” https://mp.weixin.qq.com/s/AOLQ6Dy6SCy4uEgCaHj8-g  【`2.18`】

一文吃透Linux进程间通信，告别“社恐”进程！ https://mp.weixin.qq.com/s/gDzhtb_zXLO0rHGmBp04cA  【`2.16`】

打破边界，Linux环境下的内存越界调试技巧 https://mp.weixin.qq.com/s/FiwncETvun9TWRZyTm_Llw  【`2.15`】

吐血整理 | 肝翻linux内核调试技术汇总 https://mp.weixin.qq.com/s/wXSZqi50d24lMu7AEAMDRQ  【`2.11`】

Linux性能优化实战，网络丢包问题分析 https://mp.weixin.qq.com/s/QUKlaRI__M2K038bjeGWtw  【`2.8`】

优化代码性能：利用CPU缓存原理 https://mp.weixin.qq.com/s/bkEi2JsK876LtkC8Ow9dTA  【`2.4`】

跨越通信障碍：深入了解ZeroMQ的魅力 https://mp.weixin.qq.com/s/Ssk3m2CWorn0ejgMPDo9lQ

Linux性能分析神器ftrace：从原理到实战 https://mp.weixin.qq.com/s/um5g8CkMcC9YTaP72miHCA

# 01

解锁Linux共享内存：进程通信的极速引擎 https://mp.weixin.qq.com/s/cwvnOeZVm3ehnhdjbTBLag

Linux网络编程中的零拷贝：提升性能的秘密武器 https://mp.weixin.qq.com/s/YXcXFXjzdKojWhIzSqHnMg

Linux内核追踪机制：性能监控与故障排查 https://mp.weixin.qq.com/s/TMQjHFLctuAWwOJzS2Rgow

C++性能优化指南：探索无锁队列设计与实现 https://mp.weixin.qq.com/s/-9RJgcpamtXZOFflOkkt5w

解锁C++性能密码：TCMalloc深度剖析 https://mp.weixin.qq.com/s/c08cT7S_WnR9ceBvaQYlAg

深入解析网络IO底层原理：实现高效的数据通信 https://mp.weixin.qq.com/s/rD0zA4EcQZVr92fM4f1IwQ
