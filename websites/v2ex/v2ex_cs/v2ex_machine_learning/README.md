
🙏🏻🙏🏻🙏🏻我是个小公司桌面运维，老板让我给他开发个 AI 大模型…… https://www.v2ex.com/t/1066362
- > https://www.v2ex.com/t/1022439#reply81 感觉参考这个思路，就是把文集构建向量数据库，然后搞个开源大模型，或者购买个大模型 AI 接口 查询问题时，先查向量数据库，然后把结果给大模型，然后让大模型在回答。

深度学习，人工智能，请问哪本书可以入门，感谢 https://www.v2ex.com/t/957914
- > Sklearn 与 TensorFlow 机器学习实用指南第二版 https://hands1ml.apachecn.org/#/
- > https://playground.tensorflow.org/ 甚至可以直接让孩子当小游戏玩。
- > 同推荐 吴恩达在 Coursera 上的两门课程
- > 楼上推荐的这些都是做算法设计类的 如果是做应用 你可以 B 站看看 yolov5 大多数应该都是直接用 github 上开源的算法加上自己的数据集
  >> Yolov8 更简单, 源码 clone 下来, 一行命令就能跑
- > Keras 那本我觉得很不错
- > B 站大学 李宏毅。。。
- > 李沐的动手学深度学习！ https://zh.d2l.ai/

ChatGPT 还不是最可怕的 https://www.v2ex.com/t/899927
```console
ChatGPT 有多牛逼，大家应该知道了。
GPT3 模型有 1750 亿个参数，ChatGPT 是基于 GPT3.5 。
但是即将发布的 GPT4 模型有 100 万亿个参数。
所有文本类（包括编程）工作，都降产生巨大的变革。。。而且这一切都会发生在 3 年内
```
- > 我一直有个想法：每个人从会说话开始就用一个 AI 收集他的信息，这样收集一辈子之后，后续和这个 AI 聊天可能就与本人差别不大了。另外，一些特别受欢迎的人，还可以卖自己的 AI ，让倾慕者有与他随时相伴的感觉。
- > 然而只是无脑模式匹配算法的量变不是质变，和真正的能逻辑推理的人类智能完全不是一个东西，甚至可以说还没起步
- > 推上有一个人给他做了 IQ 测试 https://twitter.com/SergeyI49013776/status/1598430479878856737
- > 再牛逼也写不出李白那种水平的诗
- > 题主搞了个大新闻啊，哪里说 GPT4 有 100 万亿参数......我怎么看到说在 GPT-3 和 Gopher (175B-280B)之间，很多研究其实发现数据量也很关键，GPT3 是欠训练的
- > 作为 NLP 从业者，首先我对 GPT 系持怀疑态度，我就基于我的经验，发表一下个人愚见。
  * > 先不说文本生成这种难度较高的任务，就连文本分类这种最最基础的任务，在很多场景下达到 95% 以上的准确率仍然是很困难的（ Bert 系），他就是学不会。楼上有人说模型参数量很大，有人说模型不是单纯记训练集，可是现实是，模型很可能就是在背书，参数量越大背得越好。
  * > 不知道大家有没有想过，GPT 这种 LLM （ Large Language Model ）的训练集是非常之巨大的，那么在评测模型的时候，也就是在测试集中是不是有可能出现训练集中的数据或者类似数据？这个现象叫 benchmark data contamination 。GPT 的作者也发现了这个现象，但是他已经来不及重新训练了（费用太高）。
  * > 我个人认为，现阶段模型的作用已经相对较小了，最重要的是数据，也就是 Andrew Ng 所说的 data-centric AI ，正所谓 GIGO （ Garbage In Garbage Out ），构建一个成熟稳定强大的人工智能系统，现在重点和难点已经变成如何获取干净、有效、足够的数据。模型已经基本定型，小修小改影响不了多少。
  * > 关于背书和数据的重要性，还可以参见 GitHub Copilot ，是不是很多是直接拿的现有代码（训练集）？
  * > 希望模型在背背背之后，某一天可以突然真正理解其中奥义，那时候才是真正变成了自己的知识，就像我们小时候死记硬背古诗，长大后某天突然理解了真正含义。那要造成这个突变，是数据扮演了更重要的角色还是模型？以后还难说。

用 keras 搭建出一个判断今天是周几的模型？ https://www.v2ex.com/t/844757
```console
有没有前辈，能不能教下，如何用 keras 搭建一个模型，例如

x=[[2022, 12, 31]] x.shape = (-1, 3) y=[[6]] y.shape = (-1, 1)
x 对应日期，y 对应星期几，生成从 1000 年到 2021 年所有的日期对应的周几进行训练，这种模型要如何搭建？

我用了 Dense(64, activation='relu', input_shape=(3,)) Dense(64, activation='relu') Dense(1) 模型训练，
并不能得到一个很好的结果。 刚入门，希望有前辈能给一点提示。
```
- > 有时候挺服搞机器学习的 搞了这算法那算法，一看效果还不如十几年前用 sql 写的数据分析。。。
  >> 人家这明显就是用来练习的练习题呀，我们当时作业还做过让 lstm 学习整数加法呢……
- > 推荐知乎镜像问题：如何用深度学习判断某数是否是 2 的倍数？ <br> 这类问题对这种依靠“经验”的概率模型无解 建议 OP 放弃尝试 转而去研究 cv
- > 机器学习不是魔法，需要特征工程。但是题目中的问题一旦涉及到特征工程，就和朴素的算星期几没有多少差别了。
  >
  > ps 补充“特征工程”这个论点。
  * > 如何用神经网络学习奇偶判定？直接放进去一个数是不行的，因为机器学习模型在这个问题上，任何超出训练集范围的数都是“训练分布外的数据”，不能得到有意义的输出。
  * > 正确的方法是比如，转换成二进制，拆成若干 0/1 串。。。。那恭喜你，正确答案就是看最低位的。这个机器学习能学到。但是已经转换成二进制了，那和直接写出奇偶判定的程序，也差别不大了。
  * > 当然你也可以转换成四进制、八进制，十进制，六进制。这几个进制对于奇偶判定的问题都比较 easy 。若是转换为三进制、五进制，多看几位应当也能搞定。这就是机器学习和人做奇偶判定程序有区别的地方了，人的话必须先二进制，然后才能给答案，第一步特征工程必须非常精确。但是机器学习的话，稍微有点偏差，给个 X 进制，也能凑合着学出来。所以它比普通的程序算法要稍微“智能”那么一点。
- > 神经网络很难做取模运算吧。可以试试输入二进制化后的一堆 0 和 1 ，输出改成分类而不是直接输出 1 个数字。
- > 如果不怎么在乎实现难度的话可以考虑把年月日转换成 embedding 输入。
- > 虽然在工业实践上不该这么做，但在学术上研究这些问题是有意义的
- > 我记得 莫烦 有个类似的例子, 但一下找不到了, 你找找看
  >
  > 找到了, 莫烦的例子是 https://mofanpy.com/tutorials/machine-learning/nlp/seq2seq/ 
  ```
  # 中文的 "年-月-日" -> "day/month/year"
  "98-02-26" -> "26/Feb/1998"
  ```
  > 当然, 你这个模型要比莫烦这个例子难不少, 有没有解都不好说.建议入门时选一些难度适宜的
- 个人补充：
  * 能否使用神经网络来判断奇偶数？ - 知乎 https://www.zhihu.com/question/364113452
