
停止对瀑布模型的污名化 https://www.v2ex.com/t/1056100
- > 严重同意，现在很多敏捷不过是在向金主无底线妥协
- > 敏捷开发是向上管理，老板每天、每时都能看到进度。瀑布是向下放权，老板只能到某个节点知道一个进度，开发甚至能决定哪部分要优先开发。个人暴论：敏捷就是以放弃质量（能跑就行）来提升所谓的快跑、快速迭代，一大堆技术债。
- > 非常同意，敏捷+人员流动=大量屎山
- > 敏捷的基础是有清晰的功能发展路线
- > 在不同的团队面前谈开发模型，是不可能达成一致的。瀑布模型之所以被流行趋势不认可，主要是由于： 1.集成太晚，提高交付难度。2.阶段切换之间，浪费太多生产力。 导致很直接的原因就是很难做到**按时交付**，而这个结果是致命的。
- > 所有人都知道这个东西不靠谱， 但是老板就是相信这个 顺便一提， 我现在所在的团队推敏捷， 实际落地的时候一个项目组同时负责两个 sprint 的开发。再加上潜在的线上问题运维支持的时间，以及随时都会有的 BI 协助要求 就这敏捷总监还说大家估时要准确，不要注水。不注水就死定了

[单个 6.2TB 203 亿行 的超大 csv 文件保持顺序的情况下去重]的两个解决方案 https://www.v2ex.com/t/1047722
- > 一行 shell 的事被你搞得这么复杂，6TB 可以存内存里，6PB 呢？看不下去了，这个源码也不愿意给，我直接给出结论：
  ```shell
  awk '{print $0","NR}' input.csv | sort | sed -E 's/,[0-9]+$//' | uniq
  ```
  * > 其中 input.csv 替换成你的输入文件，结果将出现在 stdout ，如果要存到文件，自己重定向一下即可。
  * > 不管你的电脑内存是 1T 还是 1G ，都可以正确运行并得到相同输出，因为 sort 命令用的是归并排序，是外存算法。如果你要限制用到的内存大小，把 sort 改成 `sort --buffer-size=100M` ，即可限制只用 100M 内存，其他命令都是行缓存算法，只会保存当前行在内存里，也就是说，最大内存用量是 max(100M, max_line_size_bytes)

[单个 6.20TB 的超大 csv 文件保持顺序的情况下进行去除重]各个方案的可行性分析 https://www.v2ex.com/t/1046610

要对单个 6.20TB 的超大 csv 文件保持顺序的情况下进行去除重复行，有什么好思路？显然不可能加载进内存 https://www.v2ex.com/t/1046023
- > duckdb 值得拥有
  >> 看错了，还以为是 6GB 的 csv 文件在线处理呢，那确实不适合 duckdb 。还是上 spark 吧，硬盘配大点就行。203 亿行 csv 有那么大吗，我们每天备份全量的 17 亿行信息，保留几十天，用 orc 存储，也就几百 G 。
- > 行数是 203 亿，平均行长 335 <br> 去重是基于整行文本 <br> 前缀重复度不高，没有 ID <br> 最高可以弄到 256GB 内存的服务器
- > 感觉可以试试 clickhouse 。
- > 直接存入 kvrocks (硬盘版 redis)
- > https://www.emeditor.com/text-editor-features/large-file-support/files-up-to-248gb/
- > 可以试试 polars streaming + file sink ？ https://www.rhosignal.com/posts/streaming-in-polars/
- > 惊了～ 竟然没人提到 RocksDB 吗？ 本地的文件型 KV 存储库，内置 bloomfilter ，磁盘空间够用，应该很简单的

多线程分段下载文件时，为什么不下载到同一个大文件中？而是要分别下载到单独的文件然后再合并。 https://www.v2ex.com/t/1039715
- > 没有为什么，就是写代码的太菜，连 pre-allocate+seek 都不会
- > 实际上除了 IDM 主流下载器都是不需要合并的
- > 首先，迅雷、FDM ，都是下载到同一个大文件里的。这种方式，首先需要申请这个文件的空间，也就是你刚开始下载 10g 的文件，立刻就要在硬盘里创建 10g 的文件。然后，写数据是一个持续的过程，多线程需要自己调度好文件占用的问题。你 demo 是等 10 秒后一次性写入。分段需要处理临时文件，各有优劣，看自己更熟悉哪种方式了。
  >> 我以前做过多线程下载器，关于文件分配，直接向 OS 申请预分配一块存储空间就行了，预写入 10G 那是 HDD 时代老 Windows 的东西。关于线程调度，直接开个 `BlockingQueue<<Index, ByteBuffer>>` 然后由专门的 Writer 负责写就行了，其他下载线程只需要负责把下到的 block(比如设定每个 block 为 512K)挂到 queue 上就完事 <br> IDM 那种分文件下载再合并，对于大文件下载来说是不可接受的开销。除了菜逼我不知道还有什么理由会这样做

Excel 内容转成 CSV，容量大了一倍 https://www.v2ex.com/t/956953

【[:star:][`*`]】 条件传送指令，就比条件转移指令要好吗？ https://www.v2ex.com/t/900026
> ![](https://s3.uuu.ovh/imgs/2022/12/04/c823dbeff36d5a88.png)
```console
上图给出了不好的理由，因为转移指令会影响分支预测。（上图来自书籍：x86 从实模式到保护模式）
但是条件传送指令，也是依赖于标志位来决定是否执行动作的呀（第二段），那岂不是也会影响分支预测啊？
```
- > 条件分支需要改变程序计数器并加载不同的指令，条件赋值指令无论指令的效果如何都不改变接下来马上要执行的指令，只会产生数据依赖。 <br> 或者你可以简单地认为条件赋值是某种非常常见且特殊的条件分支，设计成专门的指令是为了让 CPU 从指令级别识别出来这种特殊的条件结构并优化（不可期待 CPU 识别一个条件分支指令的实际效果相当于条件赋值并优化，因为识别这种特殊性需要时间）。
- > 您提到的条件传送指令（ cmovcc ）和条件转移指令（ jcc ）都是根据标志位来决定是否执行指定的操作的。但是，条件传送指令与条件转移指令在执行方式上是有区别的。 <br> 条件传送指令是通过传送数据来实现条件执行的。如果条件成立，条件传送指令会将指定的数据传送到指定的寄存器中；否则，条件传送指令不会执行任何操作。 <br> 因此，条件传送指令并不会改变程序的流程，所以它并不会影响分支预测。
- > 这本书话没讲完所以楼主有点困惑。
  * > 首先它说了，条件跳转会影响分支预测。那楼主有没有想过，为啥要分支预测，啥叫分支预测？
  * > 现代 CPU 是流水线结构，同一时间可能有前后一共 20 条指令在并行执行，每个执行每一条指令的不同步骤。对没错，指令是有多个步骤的。这种并行执行指令的不同步骤的做法，叫作流水线。
  * > 想必楼主发现盲点了。对于一个条件跳转指令而言，一共两个分支。那在 20 指令流水线里面，当跳转指令第一次装入这个流水线之后，到底哪个分支应当作为接下来的指令装入流水线？请注意，在跳转指令执行完成之前就必须开始执行接下来的指令了。这里就引入了分支预测，在分支跳转执行完之前就假定接下来是哪个分支被执行，然后开始激进地执行那个分支的接下来 19 条指令。一旦预测错了，那对不起，这 19 条指令的中间结果就会被销毁，重新读取正确分支的指令开始执行。
  * > 如果分支预测错误，就会导致流水线一次失败的提前并行执行，也就是在这一瞬间你的 CPU 慢了 20 倍。如果一个程序的分支预测频繁失败，那你的程序就会慢好几倍。
  * > 上文中的条件传送，看上去就没有两条分支指令流，只有一条。所以就不存在流水线失败的情况，也就和分支预测没有关系了。
- > 老夫优化程序 20 年，因为分支预测导致的性能显著下降的案例只在教学示例中遇到过，新一些的处理器（ 2 ，3 代至强）分支预测基本上>98%正确率；可以说影响现代计算密集型程序性能的主要因素已不在程序逻辑而在于结构体设计。

最近在练习正则,大家有没有什么在线的类似于用正则实现的通关类打怪练习正则的在线网站吗? https://www.v2ex.com/t/875808
```console
统一回复:感谢诸位的推荐 下面是收集大家推荐的网址,方便需要的朋友
https://www.hackerrank.com/domains/regex
https://callumacrae.github.io/regex-tuesday/challenge20.html
https://regexlearn.com/
http://alf.nu/RegexGolf
https://regexone.com/
https://regexcrossword.com/
https://regex101.com/
https://t.me/LDList/654
https://store.steampowered.com/app/1489660/Copy_Editor_A_RegEx_Puzzle/
https://ihateregex.io/playground/
https://github.com/Bowen7/regex-vis
```

base64 编码图片一般会使体积变大多少？ https://www.v2ex.com/t/847238
```console
客户要求把用户上传的 8~9MB 照片全部 base64 保存进数据库防止被传马，API 直接返回 base64 ，给他解释 base64 会让图片变大他理解不了
```
- > 自己搭建图床系统，数据库只存图片路径
- > 36 <br> This encoding causes an overhead of 33–36% (33% by the encoding itself; up to 3% more by the inserted line breaks). 来源 维基百科 Base64 <br> 但是 gzip 可以解决一部分
- > 数据库存 blob 呗，base64 何必呢
- > 三个字节的原文会变成 4 个字节的 Base64 编码。
- > base64 的有效数据 75%，所以会增大 33.333%
- > Base64 ，故名思义，64 进制（ 2^6 ），一个字符表示 6 个比特数据 <br> 一个字符计算机储存为 8 个比特，多出来(8-6)/6 = 1/3 = 33.33%
- > 说出来你们可能不信，base64 增大的那 33%，只要用目前较强力的压缩算法，比如 7z ，又可以把增大的部分给压回去。 <br> 所以 base64+7z, 可能最终对比原图 JPG 大小，也就大个 5%。
  >> 7z 以后还是 blob 数据，那么既然如此，为何还要走 base64 -> 7z 这条路，直接图片本身 blob 入库。最后结果是一样，而且这么兜了一圈以后，base64 浪费一遍 CPU 资源，zip/unzip 又费一次 CPU 。
- > 话说这让我联想起 9 年前，和客户吃饭时客户专门带上懂电脑的朋友，试探性的问了我一句如果被 DDOS 了怎么办。 <br> 我那时候回复是只能硬抗，要么上设备清洗要么加大带宽。 <br> 然后他似笑非笑的说为什么不把 DNS 改为 127.0.0.1 <br> 当时我很无语，随后问他那拔网线不是更快......
  >> 这位改 dns 解析思路异于常人，卖服务的怎么就没想到这个点子呢。
- > 我以前搞过一次 做一个新闻页 需要上传图片 领导不给文件服务资源 我就把图片转 base64 存数据库🤣
- > 33%，可以根据这个工具 https://devtool.tech/base64 ，看一下编码的过程，为什么是 33% 一目了然。

才发现网线插不好也会降速 https://www.v2ex.com/t/847384
- > 网线不能盘，有电气干扰
- > 说个类似的事，我的树莓派 4b ，之前安装的官方 RPi10 ，一点问题没有，后来我升级安装到 Rpi11 ，每次启动就黑屏，根本进不了系统，全新安装也不行，刷回 10 就没事，装 Ubuntu 也不行，又换 U 盘又换存储卡又升级固件，折腾了十来遍吧，就是不行，我都怀疑是不是板子有暗伤，后来把外壳拆了居然都没问题了。后来发现是壳子有点厚，导致 HDMI 线插得不够深，其实系统启动起来了只是没有输出到显示器。但是老版本系统居然没问题，这就很奇怪了，难道 HDMI 线还有功率么。
- > 绿联就算了吧。。。我好多问题都出自绿联 比如网线，hdmi 线。。都换了 换成别的品牌了 比如飞利浦
- > 同样出现过这种情况，用一条二十米的六类扁线连路由器，反复出现使用一段时间后掉到百兆，重新插拔后恢复千兆，然后再次掉到百兆。自从换了条圆线后再也没有出现过这种情况
- > 扁线除了好看点，其他真没啥优点了。0.5M 的短线都有可能出问题
- > 我公司同事网线弯了接触不良，以太网直接掉到 10mbps ，重做水晶头无效，换线才解决。

如何把一段简单的代码变复杂？ https://www.v2ex.com/t/845726
- > 好奇就去搜了一下，给你配段代码 <br> 他这个名字叫 Hello World Enterprise Edition ，很形象了 <br> https://gist.github.com/lolzballs/2152bc0f31ee0286b722
- > 早上才在知乎看到，虽然很多年前已经看到过 
- 个人补充：
  * 如何把一段简单的代码变复杂？ - 知乎 https://www.zhihu.com/question/277243683

练习两年半的同事写的代码 https://www.v2ex.com/t/825212

问一个协程方面的问题 https://www.v2ex.com/t/821871
- > 协程主要针对的场景是 IO 阻塞的时候能够有轻量高效的处理大批量并发任务。对于大量并发的 CPU 开销（运算）来说，协程毫无用处，因为协程并不能协调 CPU 资源，比如控制 ffmpeg 压缩视频这事，你用协程就没办法，因为 CPU 核就这么几个，你并发上万个协程也没法变出更多的 CPU 资源出来，反而会因为过多的切换而更慢。
- > 
  ```
  并发种类：
  1. 多线程：太慢
  2. callback：代表作为 Node.js 、python tornado ，boost asio 。但是会陷入 callback 地狱。
  3. Promise / Future：java, scala, js, 比 callback 好多了，目前是主流技术之一。缺点是要仔细管理闭包的嵌套。
  4. event loop：一般 c/c++ libev libuv ，还有 python gevent 。心智负担比上述三种都大，但是可以更精细操作、更高效。底层实现一般为 kqueue 和 linux 上的 epoll ，或者 fallback 到 select 。
  大名鼎鼎 nginx 就靠 event loop 暴打同时代。
  1. 协程。
  
  协程一般用 event loop 实现，这种协程就是对 event loop 的抽象。要理解协程，建议稍微学习一下 event loop 。
  ```
- > 所以说协程就是一个封装的方法问题？ 如果遇到阻塞 IO ，协程就没用了？ <br> 目前我只知道网络是非阻塞 IO ， 并且这个是操作系统支持的，java 高性能的 网络框架性能也很好的点在于 网络非阻塞 IO ，放到任何语言里都是。 <br> 我所说的协程其实根本和性能无关？ 我应该吧协程和 callback 或者 event loop(目前还不太清楚是啥) 等 解决并发的方式来比较对吗？
  >> 1.对，协程只对非阻塞 IO 起作用。 <br> 2.但其实，所有上述的并发方法都是针对阻塞 IO 减少开销的。对于 CPU 密集型任务，如果只有 2 个核，同时跑 4 个矩阵计算是没有意义的。 <br> 3.在实践中，通常把 IO 任务和计算任务分开。IO 靠比如 Promise/Future ，event loop ，协程搞。如果需要调用计算任务，就扔到一个固定线程数的线程池上跑，然后协程进入 await。等计算完成 await 被唤醒，再继续做后面的 IO。
- > IO 的模型：以买餐为例，忽略细节 <br> 1.阻塞：经典模式接口。你到餐馆买餐，在餐馆一直等到做好打包，拿了带回来。 <br> 2.非阻塞：电话订餐，每隔小段时间重新打电话问餐馆做好没（其他时间有自由时间处理其他事情），做好了就去拿回来。这电话就是非阻塞调用，但是依然是操作系统调用，会有内核陷入。 <br> 异步：操作系统提供接口支持，也就是 event loop 模式。电话订餐，餐做好了餐馆直接电话给你通知好了，你去取餐。 <br> 协程用在 IO 密集的场景中，通常都是和 event loop 配合，简化复杂的 callback 序列。

有没有比较完整的 protobuf 教程？ https://www.v2ex.com/t/803198
- > 鸟窝的这个不错 https://colobu.com/2019/10/03/protobuf-ultimate-tutorial-in-go/

跨语言之间的调用，原理是什么？ https://www.v2ex.com/t/731019

突然想到一个问题，消息队列的意义是什么？ https://www.v2ex.com/t/730959

【[:star:][`*`]】 想到一个有趣的问题，为什么 debug 模式可以进断点而 run 模式不行？ https://www.v2ex.com/t/727396
- > 因为当在 debug 模式下一个断点时，IDE 将断点处程序的二进制替换为了 0xCC，即 INT 3 指令，当程序执行到 INT 3 时，再替换回原指令执行，而 run 模式并未做这个事。
  >> 我胡乱猜测的：目测你说的这个应该是执行的时候发生的替换（几乎不可能是修改的编译后的文件），那么非 debug 模式，按道理也能进行替换，甚至插入指令。意思就是不管是不是 debug 模式都能 debug 。 <br> 唯一想到的可能就是：非 debug 模式下不好去定位到源文件，也不好去处理变量名（也许都丢失了），然后调试器的开发者懒得去支持非 debug 模式调试😂 任何语言通用，瞎猜的，无非就是为了避免使用者来找麻烦。
- > debug 模式，编译器什么的会给生成的可执行文件加入很多调试相关的信息
- > 调试模式运行的时候，会有类似 DWARF 的调试文件生成，包含运行的指令与源文件行号、函数等信息，然后运行的时候会执行 ptrace 类似的函数，如 #1 所说，替换断点处的机器指令，可以查询当时各寄存器的值等信息。 <br> 如果有源文件的话，IDE 支持在程序运行之后再把调试器挂载到指定进程。 <br> 而普通模式运行的时候是很少与源文件相关的信息，不方便你对着源码去调试。
- > 硬件支持，操作系统提供 api，编译器提供符号，调试器提供功能，想要理解调试的原理需要很多知识
《软件调试》张银奎，这本书很不错，楼主有兴趣的话可以读一下
- > Java 其实就是开了个特殊端口给调试器调用，其他没区别了
- > C 语言的话 GCC 编译参数不一样. 生成的.o 文件也不一样. 譬如 需要将机器码和代码做映射. 另外执行方式也不同. 参考 ptrace.
- > 除了加入调试相关信息外，debug 模式通常还会禁用代码优化，保证你写的什么就生成什么。release 下代码会经过大量优化，有可能你洋洋洒洒写了一大段的计算，最后被优化成一个常量什么的。像是 C 系的还会做 unroll 或者 vectorize，不关优化的话根本没法调试的。
- > 以前 NOIP 用 Free Pascal 的时候看到文章说简单花指令 asm push pop 一下 <br> 然后看到 FP 有 asm，顺便玩了下，然后发现编译输出 debug 的话仅仅 asm push xxx; pop xxx; end; fc 一看，差了非常非常多的部分。而如果编译输出为 release，就只多了几个字节。
- > https://eli.thegreenplace.net/2011/01/27/how-debuggers-work-part-2-breakpoints
- > Java 的 debug 不是加 int 3 的，是 JVM 处理的。
- > release 模式的话，可以用 ollydb 之类的来设置断点，唔。。。。

不懂就问： Linux 默认创建的文件是什么后缀格式的？ https://www.v2ex.com/t/723038 【这个和那个“png 格式图片转成 jpeg”的帖子是类似的。】

诚心请教关于 base64 的问题 https://www.v2ex.com/t/721443
- > 如果你按二进制传输，那无所谓内容了。但是你要按文本文件传输，那二进制内容就放不进来。 <br> 举个例子，服务端和客户端通信都是用 JSON 格式，JSON 按标准是 UTF-8 Only 的，如果服务端想通过 JSON 传递一张 PNG 格式的验证码图片，那这个图片是二进制的就有问题了。比如二进制里有 '\0' 字符，而这算作 ASCII 字符串的终止符，显然不行。这时只能先 base64 编码一下才能放到 JSON 里。
- > base64 的意义就是全部用可见字符来表示一段二进制 <br> 不是所有地方都是按二进制处理的，比如 url，比如网页 <br> 这种地方你要想包含一段二进制，特别是包含不可见字符和非法字符的二进制，就必须先用可见字符编码 <br> 虽然这个用 16 进制来表示也可以，但是 base64 比 16 进制更省空间
- > base64 类似 hex 的作用，不过更省空间。
- > 举个简单的例子：文本转输协议常常以标准的 c_str 为截体，\0 作为截止符。而二进制数据中很可能存在或多或少的 \0，（还有很多不可见的控制字符），直接放在这样的协议上是传输不了的。base64 解决的就是在文本转输协议上发送二进制数据的问题。
- > 为什么说 base64 比 hex 更省空间呢？随手试了下：11111111 用 hex 表示是 FF，转换成 base64 就不止两位了
  * > 一字节太短了，HEX 是 4bit 一字符，Base64 是 6bit 一字符，加上 Base64 要进行填充，最后长度会是 4 的倍 <br> 0xFF(8bit) 的时候就是 2 vs 4，但是到 0xFFFF(16bit) 就是 4 vs 4 一样长了，0xFFFFFF (24bit) 是 6 vs 4 就反超了
  * > 你搞错了，你说的 FF 那已经是二进制了，不叫 hex 了。11111111 的 hex 是 3131 3131 3131 3131，总共 16 个字节，base64 是 MTExMTExMTEK，13 个字节
  * > hex 其实是 Base16 的别称，hex 不等同于 16 进制。
- > 以这个 rsa 加解密的简单演示为例： https://v2ex.com/t/542798#r_6999455
<br> 如果加密后的数据不用 base64 编码的话，是无法直接显示在页面上的，显示了也是乱码。乱码复制粘贴到别处就是另一份数据了，文本格式就没问题。包括 rsa 的密钥对，想写进代码里，就必须用文本格式。这就是文本格式的可读性、兼容性。
<br> 所谓的 hex，是 16 进制数据文本化。比如，你用二进制编辑器打开一份数据，肉眼可见的，就是 16 进制数据的文本化表达。HEX 只能用 16 个字符表达数据，其他文本都浪费了。当然比 base64 浪费空间。
- > 1 、部分二进制数据（加密、压缩、音频、图片、视频等算法处理后的二进制数据）方便存储为文本方便复制粘贴、存储、传输 <br> 2 、在部分协议里为了兼容协议的解析规则逼不得已用 Base64 或 HEX 文本进行特殊符号编码
- > btc 还用 base58 呢，一套编码罢了（ ipfs 最近还用 base32
- > 推荐你读一下我的两篇公众号文章  https://mp.weixin.qq.com/s/gZtUp8urhq5fivTkv8nfAQ  https://mp.weixin.qq.com/s/u2bpRJEC6BNxRLNr5p3KwQ
- > base64 的重要意义就是把各种字符都统一用 64 个基础字符（实际并不是刚好 64，别纠结这个）表示了，用来简化传输难度，传输完成后还原回去用。图片可以 base64，汉字可以 base64，ascii 字符也不冲突照样可以 base64 编码解码一下
- > https://stackoverflow.com/questions/3538021/why-do-we-use-base64

windows 不能命名文件为 con https://www.v2ex.com/t/715678
- > 难道你们不知道以前 win 系统在运行中输入 /con/con 会导致死机吗？暴露年龄了。。。
- > DOS 时代 con 就是设备的标识符，只能说明，你不懂微软的 DOS……
- > 我再说一个事，SVN 上面有两个目录，名字一样但是大小写不同，checkout 到 windows 机器上会因为重名，导致两个目录的内容被奇怪的合并到一起

不懂就问： png 格式图片转成 jpeg，到底算什么类型的图片 https://www.v2ex.com/t/713957
```console
众所周知，jpeg 的图片不能有透明背景色
那我要是将一张透明背景色的 png,修改为 jpeg 后缀，打开仍然是透明的，它算什么格式呢？
```
- > emmmm.....你用记事本打开，看前几个字符 。。后缀本身就没什么意义
- > png，能打开是因为图片浏览器并不是依靠文件后缀名来区别格式
- > 后缀只是为了方便人区分才加上去的，是文件名的一部分，并不决定文件类型 <br> 都是被 windows 惯的，用过 linux 或者其他类 unix 系统的话就不会问出这种问题了
- > 
  ```sh
  $ file wallpaper.jpg 
  wallpaper.png: PNG image data, 1280 x 1024, 8-bit/color RGBA, non-interlaced
  ```
- > 每种文件类型都有自己的编码格式呀，图片查看软件应该做了一层兼容
- > 好的图像软件都会不信任后缀,会根据文件头来判断文件格式,早期的 PS 如果把 PNG 改成 jpg 就打不开,就因为那时候 PS 按后缀去解析当然出错了,现在已经不这样了
- > https://en.m.wikipedia.org/wiki/List_of_file_signatures
- 自己搜的链接：
  * The difference between "binary" and "text" files https://dev.to/sharkdp/what-is-a-binary-file-2cf5  【[:star:][`*`]】
    + > On the other hand, the bytes `50 4e 47` at the beginning of the white image are a simple ASCII-encoded version of the characters `PNG`².
    + > So clearly, looking at bytes outside the ASCII range can not be used as a method to detect "binary" files. However, there is a difference between the two files. The image file contains a lot of NULL bytes (`00`) while the short text message does not. It turns out that this can be turned into a simple heuristic method to detect binary files, since a lot of encoded text data does not contain any NULL bytes (even though it might be legal).
  * Binary VS Text Mode for File I/O Operations https://leimao.github.io/blog/File-IO-Binary-VS-Text/
  * Difference between Text File and Binary File https://www.thecrazyprogrammer.com/2018/05/difference-between-text-file-and-binary-file.html

第一次接触会觉得比较有意思的编程技术 https://www.v2ex.com/t/711436

各位大佬，日常代码里你会主动使用 try catch 么？ https://www.v2ex.com/t/709674

某些语言的协程机制，其作用是什么，是否会造成额外的开销 https://www.v2ex.com/t/702723
- > 这种基础问题，搜索一下很难吗 https://www.zhihu.com/question/20511233 <br> 协程最大的优势，不需要进入到内核空间 <br> 对于“直接就跑了，简单粗暴，还整什么调度器”，我觉得你需要了解下为什么需要有多线程
- > 因为很多 io 需要等，吞吐量要大就必须多线程。线程创建和切换都有一定的开销 <br> 协程一般都是用 event loop 调度的，一般来说有 vm 的语言协程实现起来比多线程资源开销更小
- > 写异步回调代码麻烦，从而使用协程进行阻塞变成同步命令式调用
- > 不知道你具体说的哪个语言，协程和“无故多开线程“没有直接联系。通用原理可以理解为用户态线程，避免普通线程切换的代价，但不同语言实现机制不同所以需要具体讨论
- > 一句话解释清楚：线程由系统强行调度，可以做到几个人同时跑，协程是自己让出 CPU，这个人跑一会那个人跑一会
- > https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html
- > 因为协程的切换比线程的切换要快
- > 协程和线程 /进程的主要区别是协程切换行为是用户主动进行的，而不是操作系统进行的。 <br> 不同语言的协程实现方式不同，主要分成 stackless coroutine 和 stackful coroutine，前者比后者节省内存，也能解决栈内存分配的性能损耗。但是语法丑陋
- > go 一个协程占用的空间 4kb 并且可以动态扩容。创建一个线程的开销远大于一个协程。协程之间切换不用切换内核空间和用户空间，线程需要。 <br> 当然最方便的还是 go func 就能开启新的协程。比 java 高到不知道哪里去了
- > C++ 的协程是无栈协程，语言本身也没有提供调度功能，可以看作可以中途返回的函数。在遇到 co_await 的时候可以得到一个用于恢复执行的 coroutine_handle，后面要怎么继续运行，是单线程还是多线程都是由用户自己决定了。
- > 我的理解是这样的，不知道对不对：比如说一个时间片是 10ms，你的线程本来可以执行 10ms 的代码，这段代码里你需要进行到网络 IO，所以因为 IO 问题，这个线程才执行了 1ms 就被系统调度走，结果你这个线程才执行了 1ms <br> 如果你在线程里使用协程，因为不需要切换到内核态，那么你在用协程进行网络 IO 的同时还可以运行其它代码，这样你可以充分利用 CPU，完成这 10ms 的时间 <br> 再加上协程的资源占用不高，而且不需要切换空间，感觉这个才是重点
- > 当然有额外开销，不过起 100 万个协程很轻松，换成 100 万个线程就呵呵了
- > 原因很简单，线程资源消耗太大。
- > 且不说内核用户的切换开销，光是一个线程几 M 的内存，就已经吃不消了。
- > 是多协程工作的时候，多个协程的 IO 操作让 golang 给接管了，golang 应该有一个机制 将 IO 调用单独用一个线程来处理 派发 响应，像 epoll 调用就可以使用水平触发来 监听多个 fd，这样语言层面上，只要一个线程就能接管跟系统调用的操作，这样其它 golang 的线程就不用频繁进入内核态了，进入内核态首先要切换 MMU 的页表，L1 L2 cache 可能还会被 invalid 掉，单次内核态切换开销小，但是如果上千个线程的内核态频繁切换开销就大了，切换少了，很容易把线程给饿死，不频繁切换是不可能的。但是像 Java 这种线程池模型，你只能拿线程池死扛，没有其它好办法，因为语言层面上就没做协程，后续的版本可能会推出。
<br> 另外协程也有自己的问题，就是公平调度的问题，万一一个协程长期跑着，不退让 CPU，这样可能其它协程就饿死了，在调度算法上面还需要做很多处理，至于协程的中断，可以参考 Java 的 GC safePoint 实现，应该是使用 Linux 的 mprotect 系统调用，在特定的汇编地址下，插入一些 nop 代码，当操作系统检测到 CPU 运行到这个地址的时候，就会触发软中断跳转到 mprotect 事先设置的回调调用
<br> 有兴趣的朋友最好了解一下 epoll 跟 mprotect 调用，这两个函数读完说明书，基本上就了解协程是如何实现的了
<br> 这也是我称 golang 是虚拟机的原因，因为其协程本身就是虚拟了一套操作系统的调度功能，并且会在编译后的特定的汇编代码处插入特定指令，此时会触发一些 golang 协程系统内部机制的一些调用来完成调度功能
- > 是的,我记得在学习 golang 时看到有一个叫 netpoller 的东西,大概就是 epoll 的功能,只是 golang 利用 netpoller 来接管了网络 io 操作 <br> golang 用得不多,所以也不确定自己理解得对不对,感觉协程主要发挥空间是在 IO 密集场景
- > 另外协程这一套机制等于把协程的栈空间 全部放在 golang 整个进程的堆空间，如果频繁向操作系统申请释放内存空间，会造成内存抖动，因为现代操作系统有一套复杂的堆内存管理机制，需要整理碎片大小的内存空间，如果 golang 进程频繁申请释放内存空间，就会频繁触发操作系统的内存整理，而传统的线程，其栈空间都是预设好的，会随着调用增加，会随着返回减少，操作系统有特定的机制整理栈空间。
- > 是的，协程本身就是应付互联网的 IO 密集型场景，计算密集型，其实没有多线程的必要，很多算法并不能并行。
- > 其实简单来说，就是接管了调用，让 epoll 去完成多路 IO 复用，这样当 epoll 告诉你可以读这个 fd 的时候，就让协程回到运行态，协程应该算是被发明出来对抗回调地狱用的，毕竟大部分人习惯线性思维，而不是 callback hell
- > 所有语言的异步 IO 都需要操作系统的非阻塞支持，比如 epoll。应用注册 IO，当 IO 完成后，系统会通知应用处理对应事件，这样一个线程就能同时进行多个 IO 操作，不用被阻塞调用卡住。
<br> 拿 js 举例，无栈异步语法分为回调、Promise 、async/await 三种，第一种是回调地狱，第二种链式调用开火车，第三种用同步格式写异步，最人性化。
<br> 再拿 go 举例，有栈异步语法与同步一致，调度器会在进行 IO 时自动把协程切走。py 在没有 async 语法时用的是 gevent 有栈协程，把同步操作自动换成异步，无需修改代码。
<br> js 本身就是事件循环，无栈协程是加糖解决回调地狱。
<br> py 有两种协程，gevent 的有栈协程，asyncio 的无栈协程，都是为了提高 IO 效率。
<br> go 是有栈协程，m:n 调度，多个线程上可以运行多个协程，卡住时其他线程还会偷走多余的任务。本来一个线程只能进行一个 IO 操作，现在可以同时进行多个，提高 IO 效率。
<br> c++20 的是无栈协程，但可能有隐式分配。
<br> Rust 的是无栈协程，没有隐式分配，调度器要自己选择第三方库，基本上都有工作窃取算法。其中的无栈协程可以不用分配直接放栈上执行，也可以交给调度器作为顶层 future 执行。而且 Rust 没有 GC，实时性可以有保证。
<br> 个人认为，在各种语言中，Rust 的无栈协程是最轻量的。
- > 引入协程是为了解决 IO 阻塞问题，在高并发场景你不可能每个连接都分配一个线程去处理，这时协程的作用就体现出来了。协程比线程更加轻量级，占用资源更小。开销的话看实现，一般协程不需要很复杂的调度，在 IO 不可用时让出执行权，在 IO 就绪时重新执行，开销相对而言并不大。对于计算密集型场景而言，协程并没有什么用处，相反是个累赘。
- > 首先一点，要知道一台 4 核 4 线程的计算机, cpu 最大只能并行处理 4 个任务, 也就是说最多 4 个线程能同时跑在 cpu 上。假如一个程序，创建了 100 个线程, 那么同一时间只有 4 个线程能跑；如果我创建的是 4 个线程和 100 个协程, 虽然我也只能同时跑 4 个线程, 但是考虑到协程上下文切换以及协程本身所消耗的资源要比线程小很多, 你说哪个划算. 而且不同语言的协程方式实现不一样，并不一定需要和你说的一样需要创建一个线程来专门调度这些协程. 比如有的是栈协程(python 等), 还有 go 语言的 goroutine 调度也并不是专门给协程调度创建一个新的系统线程，而是通过 goroutine 绑定到系统线程(这个系统线程可并不是专门为协程调度服务的)
- > LZ 的疑惑应该是没有弄清楚协程本身的背景。这种本身具有切换逻辑，只是是协程思想的具体实现之一。而调度器只是作为这种实现的一种落地实现方式而已。
<br> https://zh.wikipedia.org/zh-hans/%E5%8D%8F%E7%A8%8B#%E5%90%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%AF%94%E8%BE%83
<br> 具体怎么实现和理念并不冲突的，比如协程其实也区分为 stackful coroutine 和 stackless coroutine 。是否包含调度只不过可以理解是根据不同场景的不同取舍或者设计，带有调度器并不是只有 Go 一种语言，另外多种语言也包含了调度器实现，比如 Rust 、Python。Go 中比较不一样的点是 goroutine 我个人认为其实是混杂了 fiber 和 coroutine 的实现的，既有用户态线程实现又有 coroutine 的内容，主要是为了解决实现用同步方式编写异步代码的需求。

问下大佬 6 楼和 4 楼能共享宽带吗？ https://www.v2ex.com/t/700420
- > 有专用的无线桥接器，不过楼主这种情况普通路由器桥接就绰绰有余了
- > 定向天线，我用的水星的一款，说是 15 公里，我七八百米，中间隔着一栋高层没问题

昨天和领导一起面试了一个牛逼疯了的前端高级开发/前端架构师 https://www.v2ex.com/t/696441
```console
然后因为难得遇见这种大佬，我就自己算是请教了几个问题。

第一，如果是很大的项目，需要部署多个服务器。
那怎么提前预估，需要的带宽，机器配置，机器数量。
他吧啦吧啦说了些，我就听懂了个他说之前有在华为做过，自己遇到就参考华为的方案。

第二，我问他如果是多服务部署，做了负载均衡。
那么一个用户在 A 服务器登录了，后面的请求又被负载均衡到了 B 服务器上。
那这个用户的登录信息，session 信息怎么办。
他说服务器之间会同步这些用户登录信息。
我就追问，那岂不是每一台机器都复制了一份其它服务器的登录信息？
他就说是的，然后马上说实际上他们有一个专门的服务器存储登录信息，不用互相同步。
讲完了他可能发现这个设计不对，自己说这种设计如果登录信息存储的服务器挂了，
那么可能所有服务器都会收影响。也没说后续怎么解决这个问题。

第三我问他，如果大项目，部署了多台服务器。那一天我需要更新站点,
那怎么保证多台服务都能更新好了以后再对外提供服务。
而不是出现一半服务器更新好了，一半服务器还是旧的。
他也吧啦吧啦了半天，反正我也没听懂。
```
```console
1 、维护中国门户网站 1000 万 pv 访问量，前端服务和线上更新、处理日常故障及 dns 服务维护。
2 、 负责 relay 跳转机维护及服务器账户管理。
3 、 负责 Ansible 日常维护 1000 台服务器，修改配置、按各组需
求修改 puppet 管理文件。
4 、 负责虚拟化技术实施，虚拟机批量安装部署，资源分配及资
产管理。
5 、 部署维护监控平台（ cacti 、Zabbix 、nagios ）和银行开发监控平台的维护，2018 年 11 月 - 至今
2018 年 04 月 - 2018 年 11 月 基于 Zabbix 监控+监控项目&实现邮件、微信报警

贴一段他的简历。我实话实说，我一个中级前端，我真不懂多少。
```
- > 多服务器压根就不同步会话信息。权限验证会在网关层处理，如果接口需要鉴权而本身请求权限过期(可以放在 cookie 或者 header 里)，网关层会直接 401 拦截回去。登录校验的信息会放在 redis 集群内。后端服务拿到的都是经过网关处理以后的 userId，再根据 userId 去解析当前应用的数据权限
- > 肯定是 redis 共享啊，分布式数据无非就是保证 ACID 那一套，方法是一致的，实现有很多方法
- > 
  ```
  session 这个问题

  第一可以不用 session，鉴权信息可以用 JWT Token 之类的方式去存。其他的尽量规避使用 session
  第二可以用中心化 Session，比如 Redis，通过 Redis 主从或者集群的方式提高其可用性就行了。
  第三就算不用中心化 Session，如果能保证 session 数据丢失也只是用户需要重新登陆下，无关键信息。那么就可以通过 LB 做 IP HASH，
      保证来源 IP 只落在固定的后端服务器上，那么 session 保存到服务器内存里就行了。如果服务器出了问题，大不了就是用户重新登陆下。
  ```
- > 讲真，我看了下你贴的他的简历，他的那些工作和我的差不多，而我给自己的定位为中等偏下。还有你说的 session 共享的问题，在云平台的网络层面可以做会话锁定，52L 已经讲解了这个问题源 IP 会持续指向首次访问成功的后端机器直至会话结束。
- > Header 字段做负载均衡需要 7 层 LB，IP HASH 负载均衡 4 层 7 层都可以。所以要看实际情况的限制
- > 突然想到有这么一个仓库： https://github.com/donnemartin/system-design-primer
  >> https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md
- > 用负载均衡 session 应该是放在 redis 中吧，不同的后端实例都用同一个 redis 。或者用 jwt，不过对 CPU 计算任务就增加了
- > 
  ```
  "第一，如果是很大的项目，需要部署多个服务器。那怎么提前预估，需要的带宽，机器配置，机器数量。"
  这个得看具体业务,提前预估基本等于扯淡
  
  "第二，我问他如果是多服务部署，做了负载均衡。"
  分布式集群利用 redis 存储 session 做无状态是基础常识,做后台开发第一年就碰得到
  
  "第三我问他，如果大项目，部署了多台服务器。那一天我需要更新站点,那怎么保证多台服务都能更新好了以后再对外提供服务。"
  蓝绿发布、灰度发布和滚动发布,也是很简答的东西

  全文都是槽点
  ```
- > jwt 主动失效不好搞吧，要是在 jwt 上再开发失效方案约等于重新实现 session，感觉还是 session 类的方案好些
- > jwt 最好结合 oauth2，一般失效时间 1h，定时 refresh。其实不是很适合 web 使用，更适合 api 使用。web 还是 session 简洁方便一些。
- > cookie 过时倒不至于……但现在都是多端，但 cookie 只支持 web……你要有个移动 APP 或者桌面 APP，就玩不转了。so，就需要 token 这种客户端类型无关的技术。
  >
  > cookie-session 是 web 专有的，解决不了多端的问题。用 token 替代 cookie 并不存在滥用的问题。
- > 第二，简单点是做 session 绑定，一个用户的请求只到某一台服务器，缺点是有一台服务器挂了，用户就要重新登录。 <br> 完整点就做分布式 session，所有服务器都到统一的地方获取 session 。常用的是 redis，通过 redi 集群保证高可用。
  >
  > 第三，其实是灰度发布，更新服务器前先从负载均衡，如 F5 等拉出，发布完成后再拉入。知道全部更新完成。
- > 想了想，不对吧，app 或者桌面端，他请求数据不一样走 http 请求吗？只要走 http 不就能用 cookie-session 这一套吗？

[长篇娱乐连载] 网络的那些事儿（S01E04）国内带宽的价格 (IDC/DC 行业内幕) https://www.v2ex.com/t/693018

阿里面试，一个对你而言很陌生的线上系统启动慢，你会如何排查问题？ https://www.v2ex.com/t/692719
- > 主机虚拟内存使用情况； netstat 看看 Recv-Q Send-Q 情况，有时候 DNS 反向解析也可能会导致慢或者一部分功能不可用。
- > 无脑 arthas
- > ng 查看下回复时间，排查是否网络原因；是否 io 密集型任务排查下系统 io 情况； cpu 是否高占用，如果高占用具体排查线程，是 gc 线程还是用户线程。数据库是否有慢查询，缓存连接情况，mq 消费是否正常，是否有三方接口响应过慢。大方向具体就想到那么多。
- > 是启动慢还是系统慢，如果只是启动慢，那说明线上没问题呀，加点日志，下次上线时看看启动到底哪里慢；如果是接口慢，那就看看系统负载瓶颈呗，是 cpu 满了，内存不够了还是网卡爆了
- > 启动慢又不是运行慢，模拟线上环境在线下尝试复现呗。 <br> 线上即然已经上线，启动慢就不是问题，先封禁变更放着，没必要在线上 debug。 <br> 如果线下无法复现，就在线上找个实例，从 LB 上把流量摘了，随便打点加日志折腾

谈谈我为什么喜欢声明变量时类型后置的语言 https://www.v2ex.com/t/678294

关于断言的一个疑问，希望可以和懂的人讨论一下，请不吝赐教。 https://www.v2ex.com/t/671078

最终一致性到底是什么？？ https://www.v2ex.com/t/666807
- > https://zhuanlan.zhihu.com/p/47445841 
  <br> 单机场景一致性主要看并发隔离 
  <br> 分布式场景一致性主要看怎么获得全序关系 
  <br> 一致性门道很多，不系统性的学习根本就弄不清楚的；可以看看 DDIA 这本书
- > 不要弄混 ACID 中的 C 和 CAP 的 C，前者的重心在于系统整体的一致性, 后者指的是多个副本之间的一致性
- > 14 楼说得并不对，理解太浅显 
  <br> ACID 里面的 C 定义非常模糊，与业务定义有关，ACID 这几个概念就不正交；单机数据库谈论 ACID 比较多，AID 是对 C 的约束 
  <br> CAP 里面的 C 也不是指什么副本一致，而是指线性一致性（也就是大家谈论的强一致，但其实大部分人自己是说不清楚什么是强一致的），还是去看书吧，这个需要扎实的理论基础
- > 分布式事务的一致性还是事务的一致性，即业务层面定义的一致性。分布式事务相对与单机事务的难点是：因通信不稳定，参与事务的各个‘进程’如何对状态达成一致。这是个共识问题。
至于 CAP，通常网络 P 很可能发生，无法避免（看到有人说谷歌自建网络非常稳定，不会出现 P ）。所以只能在 CA 上做权衡，C 强一点，A 就弱一点。CA 好像是某个概念（延迟？）的一体两面。建议参考 
  * > http://jepsen.io/consistency
  * > https://www.zhihu.com/people/zhangshuai89/posts
    + CAP，ACID，我们能做什么 - 张帅的文章 - 知乎 https://zhuanlan.zhihu.com/p/37076900

请教一下，阅读 Linux Kernel 最快的解决方案（@Windows）是啥呢? https://www.v2ex.com/t/656319
- > https://elixir.bootlin.com/linux/v5.6-rc7/source
- > https://elixir.bootlin.com/linux/latest/source
- > qtcreator，很久前看内核源码是用这个，现在 c/c++源码基本也是这个。另外，添加源码的时候，不要把所有`**_arch` 都加到工程，只加关注的几个
- > neovim + ctags，然后用 vim 插件 leaderF，堪称搜索神器
- > 使用 sourcegraph https://sourcegraph.com/github.com/torvalds/linux

关于 RSA 的一些趣事 https://www.v2ex.com/t/655096

做一个基础很扎实的程序员是一种什么感受啊 https://www.v2ex.com/t/561411
- > 现在开始学基础也不会晚。最近也一直在看计算机基础相关圣经。我整理了一个计算机基础书单，可以参考参考 https://github.com/tagnja/resources-of-learning/blob/master/%23cs-foundations.md

推荐几篇零知识证明技术博客文章 https://www.v2ex.com/t/586006
> 深入浅出区块链 https://learnblockchain.cn/

翻译了一下破解编码面试这本书，放到 GitHub 上了 https://www.v2ex.com/t/609497
> https://github.com/F8F-1BearCat/CtCI-6th-Edition-CN

:u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272::u5272:
