
# 06

In-Process Analytical Data Management with DuckDB https://www.infoq.com/articles/analytical-data-management-duckdb/
- > **Technical Perspective of DuckDB**
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/17figure-3-1686238750825.jpg)
  * > DuckDB processes this query through standard phases: `query planning`, `query optimization`, and `physical planning`, and ***the `query planning stage` is further divided into so-called `pipelines`***.
  * > For example, this query has three pipelines, defined by their ability to be run in a streaming fashion. ***The streaming ends when we encounter a `breaking operator`, that is an operator that needs to retrieve the entire input before proceeding***.
- > **Row-at-a-time**
  * > To understand how DuckDB processes a query, let's consider first the traditional Volcano-style iterator model that operates through a sequence of iterators: every operator exposes an iterator and has a set of iterators as its input. || 为了了解 DuckDB 如何处理查询，让我们首先考虑通过一系列迭代器进行操作的传统 Volcano 风格迭代器模型：每个运算符公开一个迭代器并将一组迭代器作为其输入。
  * > The execution begins by trying to read from the top operator, in this case, the GROUP BY BUILD phase. However, it can't read anything yet as no data has been ingested. This triggers a read request to its child operator, the projection, which reads from its child operator, the HASH JOIN PROBE. This cascades down until it finally reaches the sale table. || 执行从尝试从顶部运算符（在本例中为 `GROUP BY BUILD` 阶段）读取开始。但是，由于尚未提取任何数据，因此它无法读取任何内容。这会触发对其子运算符（投影）的读取请求，该请求从其子运算符（ `HASH JOIN PROBE` 读取。这会逐级向下，直到最终到达 sale 表。
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/2figure-7-1686238750824.jpg)
  * > The sale table generates a tuple, for example, 42, 1233, 422, representing the ID, revenue, and tax columns. This tuple then moves up to the HASH JOIN PROBE, which consults its built hash table. For instance, it knows that ID 42 corresponds to the company ASML and it generates a new row as the join result, which is ASML, 1233, 422. || sale 表生成一个元组，例如 `42 、 1233 、 422` ，代表 ID、收入和税额列。然后，此元组向上移动到 `HASH JOIN PROBE` ，后者查询其构建的哈希表。例如，它知道 ID 42 对应于公司 ASML，并生成一个新行作为连接结果，即 `ASML 、 1233 、 422` 。
  * > This new row is then processed by the next operator, the projection, which sums up the last two columns, resulting in a new row: ASML, 1355. This row finally enters the GROUP BY BUILD phase. || 然后，这个新行将由下一个运算符（投影）处理，该运算符将最后两列相加，得出一个新行： `ASML ， 1355` 。此行最终进入 `GROUP BY BUILD` 阶段。
  * > This tuple-at-a-time, row-at-a-time approach is common to many database systems such as PostgreSQL, MySQL, Oracle, SQL Server, and SQLite. It's particularly effective for transactional use cases, where single rows are the focus, but it has a major drawback in analytical processing: it generates significant overhead due to the constant switching between operators and iterators. || 这种一次处理一个元组、一次处理一行的方法在许多数据库系统中很常见，例如 PostgreSQL、MySQL、Oracle、SQL Server 和 SQLite。***这种方法对于以单行为中心的事务用例特别有效，但在分析处理中有一个主要缺点：由于运算符和迭代器之间不断切换，会产生大量开销***。
  * > One possible improvement suggested by the literature is to just-in-time (JIT) compile the entire pipeline. This option, though viable, isn't the only one. || 文献中建议的一个可能的改进是 `just-in-time` (`JIT`) ***编译整个管道***。这个选项虽然可行，但并不是唯一的选择。
- > **Vector-at-a-time**
  * > Let's consider the operation of a simple streaming operator like the projection. || 让我们考虑一下像投影这样的简单流式操作符的操作。
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/3figure-8-1686238750825.jpg)
  * > We have an incoming row and some pseudocode: input.readRow reads a row of input, the first value remains unchanged, and the second entry in the output becomes the result of adding the second and third values of the input, with the output then written. While this approach is easy to implement, it incurs a significant performance cost due to function calls for every value read. || 我们有一行输入和一些伪代码： input.readRow 读取一行输入，第一个值保持不变，输出中的第二个条目成为输入的第二个和第三个值相加的结果，然后写入输出。虽然这种方法很容易实现，但由于每次读取值时都要调用函数，因此会产生很大的性能成本。
  * > An improvement over the row-at-a-time model is the vector-at-a-time model, first proposed in "[MonetDB/X100: Hyper-Pipelining Query Execution](https://www.cidrdb.org/cidr2005/papers/P19.pdf)" in 2005. || 一次一行模型的改进是一次向量模型，该模型于 2005 年在[“ MonetDB/X100：超流水线查询执行 ”](https://www.cidrdb.org/cidr2005/papers/P19.pdf)中首次提出。
  * > This model processes not just single values at a time, but short columns of values collectively referred to as vectors. Instead of examining a single value for each row, multiple values are examined for each column at once. This approach reduces the overhead as type switching is performed on a vector of values instead of a single row of values. || 该模型不仅一次处理单个值，还处理短列值（统称为向量）。它不是检查每行的单个值，而是一次检查每列的多个值。这种方法减少了开销，***因为类型切换是在值向量上执行的，而不是在单行值上执行的***。
  * > The vector-at-a-time model strikes a balance between columnar and row-wise executions. While columnar execution is more efficient, it can lead to memory issues. By limiting the size of columns to something manageable, the vector-at-a-time model avoids JIT compilation. It also promotes cache locality, which is critical for efficiency. || 一次一个向量模型在列式执行和行式执行之间取得了平衡。虽然列式执行效率更高，但可能会导致内存问题。***通过将列的大小限制为可管理的程度，一次一个向量模型可避免 JIT 编译。它还促进了缓存局部性，这对于效率至关重要***。
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/3figure-10-1686238750825.jpg)
  * > The graphic, provided by Google's Peter Norvig and Jeff Dean, highlights the disparity between the L1 cache reference (0.5 nanoseconds) and the main memory reference (100 nanoseconds), a factor of 200. Given that L1 cache reference has become 200 times faster since 1990 compared to memory reference, which is only twice as fast, there's a significant advantage in having operations fit within the CPU cache. || 该图由 Google 的 Peter Norvig 和 Jeff Dean 提供，突出显示了 L1 缓存引用（0.5 纳秒）与主内存引用（100 纳秒）之间的差异，相差 200 倍。鉴于自 1990 年以来 L1 缓存引用速度已提高 200 倍，而内存引用速度仅为其两倍，因此将操作纳入 CPU 缓存具有显著优势。
  * > This is where the beauty of vectorized query processing lies. || 这就是矢量化查询处理的美妙之处。
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/3figure-11-1686238750825.jpg)
  * > Let's consider the same projection of revenue + tax example we discussed before. Instead of retrieving a single row, we get as input three vectors of values and output two vectors of values. We read a chunk (a collection of small vectors of columns) instead of a single row. As the first vector remains unchanged, it's reassigned to the output. A new result vector is created, and an addition operation is performed on every individual value in the range from 0 to 2048. || 让我们考虑之前讨论过的 `revenue + tax` 预测示例。我们不是检索单个行，而是获取三个值向量作为输入并输出两个值向量。我们读取一个块（一组小的列向量）而不是单个行。由于第一个向量保持不变，因此将其重新分配给输出。创建一个新的结果向量，并对 0 到 2048 range 内的每个单个值执行加法运算。
  * > This approach allows the compiler to insert special instructions automatically and avoids function call overhead by interpreting and switching around data types and operators only at the vector level. This is the core of vectorized processing. || ***这种方法允许编译器自动插入特殊指令，并通过仅在向量级别解释和切换数据类型和运算符来避免函数调用开销。这是矢量化处理的核心***。
- > **Exchange-Parallelism**
  * > Vectorized processing being efficient on a single CPU is not enough, it also needs to perform well on multiple CPUs. How can we support parallelism? || 矢量化处理在单 CPU 上高效是不够的，还需要在多 CPU 上表现出色。我们如何支持并行性？
  * > Goetz Graefe, principal scientist at Google, in his paper "[Volcano - An Extensible and Parallel Query Evaluation System](https://paperhub.s3.amazonaws.com/dace52a42c07f7f8348b08dc2b186061.pdf)" described the concept of exchange operator parallelism. || 谷歌首席科学家 Goetz Graefe 在论文[《 Volcano - 一种可扩展的并行查询评估系统 》](https://paperhub.s3.amazonaws.com/dace52a42c07f7f8348b08dc2b186061.pdf)中描述了交换运算符并行的概念。
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/1figure-12-small-1686241029787.jpg)
- > **Morsel-Driven Parallelism**
  * > ![](https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/analytical-data-management-duckdb/en/resources/2figure-14-1686239395390.jpg)
- 相关链接：
  * `MonetDB/X100: Hyper-Pipelining Query Execution` https://www.cidrdb.org/cidr2005/papers/P19.pdf
  * ~~MonetDB/X100: Hyper-Pipelining Query Execution - 梁辰的文章 - 知乎 https://zhuanlan.zhihu.com/p/376227899~~  【//已转移】
